{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZrbc+QVQytDTTaWPsE1Cq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-A-Lopa/Neural-Network/blob/main/Neural_Network_with_Tensorflow%2C_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries for tensorflow**"
      ],
      "metadata": {
        "id": "_JaCRni1p_8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Att0lE-Yxmnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "Sys8MNdfp-Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6f49f4-3924-4fe7-ff81-cdf4402781fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape\n",
        "#60000 ---> indicates x_train has 60000 ele\n",
        "#28 by 28 ---> indicates that each digit of 60000 digits is passed using 28 by 28 2d matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__QS4KuryCW6",
        "outputId": "944ad156-81e1-4f64-8251-abfc6f517d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_LcjdbtyIXB",
        "outputId": "355ae143-4fef-4af2-95f0-944812b60188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Tl_XQcFRyRfC",
        "outputId": "94448add-d1e4-45a8-de26-07e49c9415f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
              "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
              "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
              "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
              "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
              "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
              "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-91934ff4-2de4-4d1a-b170-ced234ec2306\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
              "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
              "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
              "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
              "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
              "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
              "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-91934ff4-2de4-4d1a-b170-ced234ec2306 button').onclick = (e) => {\n",
              "        document.querySelector('#id-91934ff4-2de4-4d1a-b170-ced234ec2306').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-91934ff4-2de4-4d1a-b170-ced234ec2306 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[59000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "collapsed": true,
        "id": "mzL3k0z1ya_w",
        "outputId": "9e758570-895b-4e26-a59e-933c9676bc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 100, 254, 158,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 182, 253, 150,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        123, 247, 253,  68,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87,\n",
              "        247, 253, 147,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23, 229,\n",
              "        253, 185,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 254,\n",
              "        254,  95,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  53, 254, 253,\n",
              "        141,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  13, 213, 254, 247,\n",
              "         54,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 253, 254,  91,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 115, 253, 231,  24,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 137, 254, 135,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 136, 253,  98,   0,\n",
              "          0,   0,   0,   0,  17,  88, 132, 214, 155,  63,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 136, 253, 165,   0,\n",
              "          0,   0,   0, 102, 241, 253, 253, 253, 254, 135,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 253, 249,  66,\n",
              "          0,  37, 174, 254, 250, 146,  41, 221, 254, 135,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 170, 254, 248,\n",
              "        128, 181, 253, 254, 233,  31, 188, 239, 193,  46,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 172, 254,\n",
              "        254, 254, 254, 255, 254, 254, 254, 171,  38,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  44, 238,\n",
              "        253, 253, 253, 254, 253, 239, 128,   9,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 156, 253,\n",
              "        253, 210, 174, 175, 129,  24,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 253,\n",
              "        195,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  36, 238,\n",
              "        182,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-b7a8a061-a675-4eba-93e5-b1ff8500d5f8\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA20lEQVR4nGNgoAdI+TcPiceEKhn0/wdOjdXf/7rgkgv//ncyLjnxp3938uGS7P33Lx6XnOm/v73MOOR4r/77boZLo8bff9FoQgh/ejO83ItTUoxxwQs0SRY46///2wwMDAwMgu46QUeXHERV1vF3KQMDA0Pax79///5rRzMj5O9PJwbVdf9+TdK8iyHJuerfj4atf/+9lN/z/qAehmfW/Pv379//f//+rVbDkGPQeff3799/f983cGK4loGhgJ/h6h3GS9PhPkKW/MhwzPcDpoEQoPJuGwcuucEBAK0tVW1BwgOxAAAAAElFTkSuQmCC\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 100, 254, 158,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 182, 253, 150,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        123, 247, 253,  68,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87,\n",
              "        247, 253, 147,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23, 229,\n",
              "        253, 185,  14,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 254,\n",
              "        254,  95,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  53, 254, 253,\n",
              "        141,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  13, 213, 254, 247,\n",
              "         54,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  40, 253, 254,  91,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 115, 253, 231,  24,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 137, 254, 135,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 136, 253,  98,   0,\n",
              "          0,   0,   0,   0,  17,  88, 132, 214, 155,  63,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 136, 253, 165,   0,\n",
              "          0,   0,   0, 102, 241, 253, 253, 253, 254, 135,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  84, 253, 249,  66,\n",
              "          0,  37, 174, 254, 250, 146,  41, 221, 254, 135,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9, 170, 254, 248,\n",
              "        128, 181, 253, 254, 233,  31, 188, 239, 193,  46,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 172, 254,\n",
              "        254, 254, 254, 255, 254, 254, 254, 171,  38,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  44, 238,\n",
              "        253, 253, 253, 254, 253, 239, 128,   9,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 156, 253,\n",
              "        253, 210, 174, 175, 129,  24,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 253,\n",
              "        195,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  36, 238,\n",
              "        182,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-b7a8a061-a675-4eba-93e5-b1ff8500d5f8 button').onclick = (e) => {\n",
              "        document.querySelector('#id-b7a8a061-a675-4eba-93e5-b1ff8500d5f8').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-b7a8a061-a675-4eba-93e5-b1ff8500d5f8 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(x_train[0])#plotting the first training image\n",
        "plt.matshow(x_train[59000])#plotting the 6000th training image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "id": "zjJJY8h3yon9",
        "outputId": "cc28d106-1a59-4d4c-e879-aec6ad3a4d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d18d7318e50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyB9mD80zFVN",
        "outputId": "2f85c39d-0823-4741-ce61-ec819448821d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEKUEiqVDKoc",
        "outputId": "7a8e151c-da32-40e5-f308-7b7fc082aa82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Flattening**\n",
        "Converting 2d array of each digit into 1d array"
      ],
      "metadata": {
        "id": "WtzVDxhUIyIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_flattened = x_train.reshape(len(x_train), 28*28)\n",
        "#this will give (60000, 784) --> meaning there will be 60000 rowa\n",
        "#for each row it will have 784 ele\n",
        "#basically converting the 28 by 28 2d matrix into 784 1d matrix\n",
        "x_test_flattened = x_test.reshape(len(x_test), 28*28)"
      ],
      "metadata": {
        "id": "SU_D0LuxI1Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_flattened.shape)\n",
        "print(x_test_flattened.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipSRtBfTKjHw",
        "outputId": "7939138a-7b05-48dd-c4ed-2e76a1f7d421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_flattened[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PQGCDW70K4kK",
        "outputId": "606785a7-f319-4f42-c6ef-2041c477118a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,  67, 232,  39,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  62,  81,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0, 120, 180,  39,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 126, 163,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   2, 153, 210,  40,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 220, 163,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  27, 254, 162,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 222, 163,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 183, 254,\n",
              "       125,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 245, 163,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       198, 254,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0, 120,\n",
              "       254, 163,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,  23, 231, 254,  29,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 159, 254, 120,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0, 163, 254, 216,  16,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0, 159, 254,  67,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  14,  86, 178, 248, 254,  91,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 159, 254,  85,   0,   0,   0,  47,  49,\n",
              "       116, 144, 150, 241, 243, 234, 179, 241, 252,  40,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 150, 253, 237, 207, 207, 207,\n",
              "       253, 254, 250, 240, 198, 143,  91,  28,   5, 233, 250,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 119, 177, 177,\n",
              "       177, 177, 177,  98,  56,   0,   0,   0,   0,   0, 102, 254, 220,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 169,\n",
              "       254, 137,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 169, 254,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0, 169, 254,  57,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 169, 255,  94,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 169, 254,  96,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 254, 153,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 255,\n",
              "       153,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        96, 254, 153,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating NN model**\n",
        "sequential() --> having stack of layers in NN\n",
        "\n",
        "\n",
        "accpet every layer as one element.\n",
        "\n",
        "First, you give input layer, then hidden layer finally outout layer.The layers are added in order, without any branching or skipping."
      ],
      "metadata": {
        "id": "XaJzG6SjKsNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we write k in this line \"from tensorflow import keras\" as upperclass like Keras write all \"K\" of keras in upperclass, else if write in lowerclass, then write it in lowerclass everywhere."
      ],
      "metadata": {
        "id": "TJFFsafcNi9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "input_shape, activation are parameters so use \"=\" sign to assign value to them. As dense is function we do not use \"=\" sign."
      ],
      "metadata": {
        "id": "JdN314Y3ODtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Explaing insides of sequential***\n",
        "\n",
        "here 10 is output layer\n",
        "\n",
        "\n",
        "784 is input layer\n",
        "\n",
        "we got 784 after flattening 2d array (28 by 28) into 1d array\n",
        "\n",
        "\n",
        "(784,) --> comma indicates a tuple (only (10) is an int)\n",
        "\n",
        "\n",
        "we pass touple as the input_shape parameter expects a shape"
      ],
      "metadata": {
        "id": "n2YkEhomQpIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model = keras.Sequential([keras.layers.Dense(10, input_shape = (784,), activation = \"sigmoid\")])\n",
        "\n",
        "simple_model.compile(optimizer = \"adam\",\n",
        "                     loss = \"sparse_categorical_crossentropy\",\n",
        "                     metrics = [\"accuracy\"])\n",
        "\n",
        "simple_model.fit(x_train_flattened, y_train, epochs = 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tsFGPWOFLJZi",
        "outputId": "b1102975-3ed5-4942-88eb-039ee47e526d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7773 - loss: 17.0226\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 5.9948\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8868 - loss: 5.5023\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 5.3039\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 5.0035\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d18f155e6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The loss is high as we did not scaled them, so now we will scale them**"
      ],
      "metadata": {
        "id": "2VIqWxE0RMwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Array ele vary from 0 to 255.So to reduce loss, we divide the whole array by 255. Now, the array ele will range from 0 to 1."
      ],
      "metadata": {
        "id": "PseLMGkSZcBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled = x_train/ 255\n",
        "x_test_scaled = x_test/ 255"
      ],
      "metadata": {
        "id": "LYJOu4dnRT4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WeBBY5jiaWgJ",
        "outputId": "c4ac2869-da80-4baf-afe8-511de51e74b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01960784, 0.24705882, 0.77254902,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07843137, 0.99607843, 0.90196078,\n",
              "        0.09411765, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07843137, 0.99607843, 0.99607843,\n",
              "        0.18823529, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07843137, 0.99607843, 1.        ,\n",
              "        0.18823529, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07843137, 0.99607843, 0.99607843,\n",
              "        0.22352941, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07843137, 0.99607843, 0.99607843,\n",
              "        0.42352941, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.0627451 , 0.9372549 , 0.99607843,\n",
              "        0.56078431, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.69803922, 0.99607843,\n",
              "        0.56078431, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.69803922, 0.99607843,\n",
              "        0.56078431, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.69803922, 0.99607843,\n",
              "        0.63529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.69803922, 0.99607843,\n",
              "        0.94117647, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.44313725, 0.99607843,\n",
              "        0.94117647, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.3254902 , 0.99607843,\n",
              "        0.96078431, 0.12156863, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.30980392, 0.99607843,\n",
              "        0.96470588, 0.14901961, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.83921569,\n",
              "        0.99607843, 0.58823529, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.56470588,\n",
              "        0.94509804, 0.03137255, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.56470588,\n",
              "        0.94117647, 0.00784314, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.56470588,\n",
              "        0.99607843, 0.32156863, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.90196078,\n",
              "        0.96862745, 0.15686275, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.65882353,\n",
              "        0.81960784, 0.12156863, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled_flattened = x_train_scaled.reshape(len(x_train_scaled), 28*28)\n",
        "\n",
        "x_test_scaled_flattened = x_test_scaled.reshape(len(x_test_scaled), 28*28)"
      ],
      "metadata": {
        "id": "uhmflxgub-pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model = keras.Sequential([keras.layers.Dense(10, input_shape = (784,), activation = \"sigmoid\")])\n",
        "\n",
        "simple_model.compile(optimizer = \"adam\",\n",
        "                     loss = \"sparse_categorical_crossentropy\",\n",
        "                     metrics = [\"accuracy\"])\n",
        "\n",
        "simple_model.fit(x_train_scaled_flattened, y_train, epochs = 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BKKkBbPb7CH",
        "outputId": "a59a0e9a-0a70-4203-845c-29521ceb4b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8172 - loss: 0.7144\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.3114\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9195 - loss: 0.2868\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.2731\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2640\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d18cdbb66d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "while evaluating, we are giving new data, and label so that, we can check how good the model works using new data."
      ],
      "metadata": {
        "id": "CojBDozkwAhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model.evaluate(x_test_scaled_flattened, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZKG6ofec1Hb",
        "outputId": "11af5169-96c1-4e33-ca20-b29dbb5bb2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.3006\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26754093170166016, 0.9262999892234802]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model.fit(x_train_scaled_flattened, y_train, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUpLoLIhdFbn",
        "outputId": "d344feb2-364a-42dd-9316-2d3922fcfcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2642\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.2580\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9309 - loss: 0.2503\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9312 - loss: 0.2500\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.2480\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d18cdd40b10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "while predicting, we are using new scaled data, not label data"
      ],
      "metadata": {
        "id": "kKD_1_-yvnRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we predict on whole dataset, can not pass x_test_scaled_flattened[9900]"
      ],
      "metadata": {
        "id": "PP23NbWZwY65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross checking x_test_scaled's actual val with predicted val(using predict())"
      ],
      "metadata": {
        "id": "2ugK5O7Ixtx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(x_test_scaled[9900])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "4uYhGWRhxB05",
        "outputId": "a12887b6-6943-48ac-bd33-ec282f1afef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d18cf519b90>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = simple_model.predict(x_test_scaled_flattened )\n",
        "y_predicted[9900]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY6TFcQNuEj0",
        "outputId": "7d4d067d-1acd-4ba1-b7fd-47900d0a9498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.1312216e-03, 9.2031114e-02, 5.3228337e-01, 2.3720035e-01,\n",
              "       2.5064254e-02, 3.3119130e-01, 2.1235285e-02, 7.8496868e-07,\n",
              "       9.4982308e-01, 4.6264553e-03], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nat5n3lLun9G",
        "outputId": "64e935b2-290b-4ee2-8614-a9ecfe6ec384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **finding max value**"
      ],
      "metadata": {
        "id": "iRj9wUtlwoTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(y_predicted[9900])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT90d8uawtmL",
        "outputId": "098d77f9-dd45-4732-88ab-ef4d067390da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Confusion matrix***"
      ],
      "metadata": {
        "id": "_4qgIGcly0Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in confusion matrix --->y_test and y_predicted both data types are supposed to be same\n",
        "\n",
        "but y_test datat type is int while y_predicted datat type is whole num\n",
        "\n",
        "So, we will convert y_predicted into int datat type"
      ],
      "metadata": {
        "id": "uEvL5Q1w4Shm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIeLQYPs4Z4b",
        "outputId": "e971aa59-adc9-4c39-b0a4-a06582154382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.34519444e-03, 1.50552157e-08, 1.34107163e-02, 9.70453084e-01,\n",
              "        1.49949710e-03, 1.18061520e-01, 1.85606979e-08, 9.99845505e-01,\n",
              "        7.17124343e-02, 6.22404754e-01],\n",
              "       [4.91340935e-01, 4.67831315e-03, 9.99834239e-01, 1.36224404e-01,\n",
              "        2.26736616e-11, 8.56439769e-01, 8.42096865e-01, 2.84195033e-15,\n",
              "        1.06880695e-01, 4.71602271e-12],\n",
              "       [1.55571208e-04, 9.93132412e-01, 6.93360090e-01, 2.45037690e-01,\n",
              "        1.90907679e-02, 1.01228423e-01, 1.02661431e-01, 4.28346582e-02,\n",
              "        2.80401379e-01, 3.21801603e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted_labels = [int(np.argmax(i)) for i in y_predicted]\n",
        "y_predicted_labels[:3]\n",
        "#np.argmax() returns array ever time , so we used int() to get int val\n",
        "#i is an array of predicted probabilities (like [0.1, 0.2, 0.7])\n",
        "#np.argmax(i) returns the index of the largest value (in this case, 2)\n",
        "#That means the model predicts class 2 (the one with the highest score)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3fhO2P44qzF",
        "outputId": "f5cca7c1-00e9-4ecf-98e6-f641a0cb56bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:3]# we can see, 1st 3 values of y_test and y_predicted_labels are matching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poUsTIVr5c86",
        "outputId": "99801aed-e46e-4f17-81e5-9eb0f8bb44c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = tf.math.confusion_matrix(labels = y_test, predictions = y_predicted_labels)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUiJ5kFi3f6U",
        "outputId": "150add8a-3096-41f6-bce2-3a8b74a9bf8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\n",
              "array([[ 967,    0,    1,    2,    0,    5,    2,    2,    1,    0],\n",
              "       [   0, 1111,    5,    2,    0,    1,    3,    2,   11,    0],\n",
              "       [   7,    8,  939,   14,    9,    3,    8,    9,   32,    3],\n",
              "       [   3,    0,   21,  921,    1,   22,    2,   10,   23,    7],\n",
              "       [   2,    1,    7,    2,  928,    0,    3,    5,   10,   24],\n",
              "       [  10,    3,    7,   36,   10,  774,    7,    9,   31,    5],\n",
              "       [  16,    3,   13,    1,    8,   18,  896,    1,    2,    0],\n",
              "       [   1,    6,   26,    4,    8,    1,    0,  955,    2,   25],\n",
              "       [   7,    8,    7,   23,    9,   19,    6,   12,  876,    7],\n",
              "       [  11,    7,    1,   10,   30,    5,    0,   29,    6,  910]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding hidden layer**"
      ],
      "metadata": {
        "id": "AUWI8l-n6A8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([keras.layers.Dense(100, input_shape = (784,), activation = \"relu\"),\n",
        "                          keras.layers.Dense(10, activation = \"sigmoid\")])\n",
        "\n",
        "#here, 100 is numbers of neurons in hidden layer\n",
        "model.compile(optimizer = \"adam\",\n",
        "                     loss = \"sparse_categorical_crossentropy\",\n",
        "                     metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(x_train_scaled_flattened, y_train, epochs = 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2106a0-e09b-4554-e616-265401cf6156",
        "id": "PHXqLwky6Ij-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.4579\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.1372\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9742 - loss: 0.0870\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0689\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0497\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d18cebd48d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_scaled_flattened, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoCyTfnh65LB",
        "outputId": "bd5d48f3-b13c-4f53-dd38-5145336f3b86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9718 - loss: 0.0969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08399505913257599, 0.9750000238418579]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adding hidden layer and flattend instead of manually converting 2d array into 1d**"
      ],
      "metadata": {
        "id": "9Xs7mgmM7zE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([keras.layers.Flatten(input_shape = (28, 28)),\n",
        "                          keras.layers.Dense(100, activation = \"relu\"),\n",
        "                          keras.layers.Dense(10, activation = \"sigmoid\")])\n",
        "\n",
        "#here, 100 is numbers of neurons in hidden layer\n",
        "model.compile(optimizer = \"adam\",\n",
        "                     loss = \"sparse_categorical_crossentropy\",\n",
        "                     metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(x_train_scaled, y_train, epochs = 5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ce1ea7-dd4b-4ec6-8bab-cea7ef79e978",
        "id": "l9X3gcUv74W6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.4616\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1371\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0902\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0667\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d18d73d2690>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e18baf-7df0-4f05-c0b8-b208dbe1bf12",
        "id": "5i9AcY-VbSy_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1075\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09093868732452393, 0.9735999703407288]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eR20_KCbZ6v",
        "outputId": "dc2d7dfa-aeba-4c98-e515-306ef4ab6e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.8073419e-03, 8.7933295e-04, 4.5381349e-01, ..., 9.9994540e-01,\n",
              "        1.5254058e-01, 8.6803861e-02],\n",
              "       [1.6692247e-02, 8.5009563e-01, 9.9999565e-01, ..., 7.9250579e-09,\n",
              "        9.2241585e-01, 6.2001241e-08],\n",
              "       [5.0031539e-04, 9.9888867e-01, 1.5176906e-01, ..., 3.3518234e-01,\n",
              "        2.3615253e-01, 1.0310075e-03],\n",
              "       ...,\n",
              "       [2.1288759e-05, 4.2098782e-06, 2.4675812e-06, ..., 2.2135079e-01,\n",
              "        8.9147663e-01, 2.7030730e-01],\n",
              "       [2.2909019e-02, 5.8211870e-03, 3.5882281e-04, ..., 1.0897114e-03,\n",
              "        9.6972138e-01, 3.0917272e-05],\n",
              "       [6.6892102e-02, 4.4999679e-04, 5.4427481e-01, ..., 4.9496698e-06,\n",
              "        1.3258974e-02, 2.1938835e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GPoumG1bgtm",
        "outputId": "85f10bfe-b007-4e7b-f1fd-1ce85b65dbcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient**"
      ],
      "metadata": {
        "id": "393QngU0ZiId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5ComLE7wdsyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/sample_data/Insurance_dataset.csv\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z1s3qKcidlXp",
        "outputId": "854bb3bb-17d1-497f-aea3-4180bd8c4d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  Affordibility  Bought_Insurance\n",
              "0   22              1                 0\n",
              "1   25              0                 0\n",
              "2   47              1                 0\n",
              "3   52              1                 1\n",
              "4   46              1                 1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28ac8b0b-d5f3-4557-818c-34fc6a8df75f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Affordibility</th>\n",
              "      <th>Bought_Insurance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28ac8b0b-d5f3-4557-818c-34fc6a8df75f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28ac8b0b-d5f3-4557-818c-34fc6a8df75f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28ac8b0b-d5f3-4557-818c-34fc6a8df75f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvdPOpcMeVXX",
        "outputId": "5264ae19-9ed0-4814-dbcb-464260ed0fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "p_sMvvMPd9vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset[[\"Age\", \"Affordibility\"]], dataset.Bought_Insurance, test_size = 0.2, random_state = 25)"
      ],
      "metadata": {
        "id": "a9MMg1kLeGg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "35*0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prh4cxugiHUz",
        "outputId": "f8d8f6a2-9666-4671-804b-dbcf1e345272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UyrcRY5d6b4",
        "outputId": "f2364197-143b-4737-c756-7aa46e20d9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n",
            "7\n",
            "28\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled = x_train.copy()#we are dividing age by 100 to bring age and affordibility into sismilar scale\n",
        "x_train_scaled[\"Age\"] = x_train_scaled[\"Age\"] / 100\n",
        "\n",
        "x_test_scaled = x_test.copy()\n",
        "x_test_scaled[\"Age\"] = x_test_scaled[\"Age\"] / 100"
      ],
      "metadata": {
        "id": "VlcJhreZd9-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "collapsed": true,
        "id": "8IjdHg_PiQQ9",
        "outputId": "16778f88-d087-45bd-b20c-d932f86a5121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Age  Affordibility\n",
              "11  0.19              1\n",
              "28  0.54              1\n",
              "25  0.27              1\n",
              "31  0.91              1\n",
              "2   0.47              1\n",
              "14  0.49              0\n",
              "9   0.43              1\n",
              "0   0.22              1\n",
              "6   0.40              0\n",
              "30  0.72              0\n",
              "19  0.34              0\n",
              "13  0.50              1\n",
              "24  0.38              0\n",
              "3   0.52              1\n",
              "7   0.38              1\n",
              "1   0.25              0\n",
              "5   0.68              0\n",
              "20  0.36              1\n",
              "34  0.60              0\n",
              "8   0.54              0\n",
              "18  0.38              1\n",
              "12  0.80              0\n",
              "23  0.69              0\n",
              "22  0.49              0\n",
              "29  0.63              1\n",
              "15  0.60              0\n",
              "26  0.38              0\n",
              "4   0.46              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4e3f73a-eb31-4079-b416-c75be488995d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Affordibility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.19</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.27</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.43</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.22</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.72</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.36</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.63</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.46</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4e3f73a-eb31-4079-b416-c75be488995d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4e3f73a-eb31-4079-b416-c75be488995d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4e3f73a-eb31-4079-b416-c75be488995d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([keras.layers.Dense(1, input_shape = (2,), activation = \"sigmoid\", kernel_initializer = \"ones\", bias_initializer = \"zeros\")])\n",
        "\n",
        "#kernel_initializer is the value of weight\n",
        "#bias_initializer is the value of bias\n",
        "model.compile(optimizer = \"adam\",\n",
        "                     loss = \"binary_crossentropy\",\n",
        "                     metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(x_train_scaled, y_train, epochs = 500)"
      ],
      "metadata": {
        "id": "OYJ53qIad32o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae316e0-4e05-4228-979d-b3cc99a88a0a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - accuracy: 0.5357 - loss: 0.7808\n",
            "Epoch 2/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7804\n",
            "Epoch 3/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5357 - loss: 0.7800\n",
            "Epoch 4/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7796\n",
            "Epoch 5/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7792\n",
            "Epoch 6/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7789\n",
            "Epoch 7/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5357 - loss: 0.7785\n",
            "Epoch 8/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7781\n",
            "Epoch 9/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5357 - loss: 0.7777\n",
            "Epoch 10/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7773\n",
            "Epoch 11/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7769\n",
            "Epoch 12/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7765\n",
            "Epoch 13/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7762\n",
            "Epoch 14/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7758\n",
            "Epoch 15/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7754\n",
            "Epoch 16/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7750\n",
            "Epoch 17/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5357 - loss: 0.7746\n",
            "Epoch 18/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7743\n",
            "Epoch 19/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7739\n",
            "Epoch 20/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7735\n",
            "Epoch 21/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7731\n",
            "Epoch 22/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7728\n",
            "Epoch 23/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7724\n",
            "Epoch 24/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5357 - loss: 0.7720\n",
            "Epoch 25/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7717\n",
            "Epoch 26/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7713\n",
            "Epoch 27/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5357 - loss: 0.7709\n",
            "Epoch 28/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7706\n",
            "Epoch 29/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5357 - loss: 0.7702\n",
            "Epoch 30/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7698\n",
            "Epoch 31/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7695\n",
            "Epoch 32/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7691\n",
            "Epoch 33/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7687\n",
            "Epoch 34/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7684\n",
            "Epoch 35/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7680\n",
            "Epoch 36/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7677\n",
            "Epoch 37/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5357 - loss: 0.7673\n",
            "Epoch 38/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7669\n",
            "Epoch 39/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7666\n",
            "Epoch 40/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7662\n",
            "Epoch 41/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7659\n",
            "Epoch 42/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5357 - loss: 0.7655\n",
            "Epoch 43/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7652\n",
            "Epoch 44/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7648\n",
            "Epoch 45/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7645\n",
            "Epoch 46/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7641\n",
            "Epoch 47/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7638\n",
            "Epoch 48/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5357 - loss: 0.7634\n",
            "Epoch 49/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5357 - loss: 0.7631\n",
            "Epoch 50/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7627\n",
            "Epoch 51/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7624\n",
            "Epoch 52/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7620\n",
            "Epoch 53/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5357 - loss: 0.7617\n",
            "Epoch 54/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5357 - loss: 0.7614\n",
            "Epoch 55/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5357 - loss: 0.7610\n",
            "Epoch 56/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7607\n",
            "Epoch 57/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5357 - loss: 0.7604\n",
            "Epoch 58/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5357 - loss: 0.7600\n",
            "Epoch 59/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7597\n",
            "Epoch 60/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7593\n",
            "Epoch 61/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7590\n",
            "Epoch 62/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5357 - loss: 0.7587\n",
            "Epoch 63/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5357 - loss: 0.7584\n",
            "Epoch 64/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7580\n",
            "Epoch 65/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5357 - loss: 0.7577\n",
            "Epoch 66/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5357 - loss: 0.7574\n",
            "Epoch 67/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5357 - loss: 0.7570\n",
            "Epoch 68/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5357 - loss: 0.7567\n",
            "Epoch 69/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7564\n",
            "Epoch 70/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5357 - loss: 0.7561\n",
            "Epoch 71/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5357 - loss: 0.7557\n",
            "Epoch 72/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5357 - loss: 0.7554\n",
            "Epoch 73/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7551\n",
            "Epoch 74/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5357 - loss: 0.7548\n",
            "Epoch 75/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7545\n",
            "Epoch 76/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7542\n",
            "Epoch 77/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7538\n",
            "Epoch 78/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7535\n",
            "Epoch 79/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7532\n",
            "Epoch 80/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7529\n",
            "Epoch 81/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7526\n",
            "Epoch 82/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7523\n",
            "Epoch 83/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7520\n",
            "Epoch 84/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7517\n",
            "Epoch 85/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5357 - loss: 0.7514\n",
            "Epoch 86/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5357 - loss: 0.7510\n",
            "Epoch 87/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7507\n",
            "Epoch 88/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7504\n",
            "Epoch 89/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7501\n",
            "Epoch 90/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7498\n",
            "Epoch 91/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5357 - loss: 0.7495\n",
            "Epoch 92/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7492\n",
            "Epoch 93/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7489\n",
            "Epoch 94/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5357 - loss: 0.7486\n",
            "Epoch 95/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7483\n",
            "Epoch 96/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7480\n",
            "Epoch 97/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5357 - loss: 0.7477\n",
            "Epoch 98/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7475\n",
            "Epoch 99/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7472\n",
            "Epoch 100/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7469\n",
            "Epoch 101/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5357 - loss: 0.7466\n",
            "Epoch 102/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7463\n",
            "Epoch 103/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7460\n",
            "Epoch 104/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5357 - loss: 0.7457\n",
            "Epoch 105/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5357 - loss: 0.7454\n",
            "Epoch 106/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5357 - loss: 0.7451\n",
            "Epoch 107/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7449\n",
            "Epoch 108/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7446\n",
            "Epoch 109/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7443\n",
            "Epoch 110/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7440\n",
            "Epoch 111/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7437\n",
            "Epoch 112/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7435\n",
            "Epoch 113/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7432\n",
            "Epoch 114/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7429\n",
            "Epoch 115/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7426\n",
            "Epoch 116/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7423\n",
            "Epoch 117/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7421\n",
            "Epoch 118/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5357 - loss: 0.7418\n",
            "Epoch 119/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7415\n",
            "Epoch 120/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7413\n",
            "Epoch 121/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7410\n",
            "Epoch 122/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7407\n",
            "Epoch 123/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7405\n",
            "Epoch 124/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7402\n",
            "Epoch 125/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7399\n",
            "Epoch 126/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5357 - loss: 0.7397\n",
            "Epoch 127/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7394\n",
            "Epoch 128/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7391\n",
            "Epoch 129/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7389\n",
            "Epoch 130/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7386\n",
            "Epoch 131/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7383\n",
            "Epoch 132/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5357 - loss: 0.7381\n",
            "Epoch 133/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7378\n",
            "Epoch 134/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7376\n",
            "Epoch 135/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5357 - loss: 0.7373\n",
            "Epoch 136/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7371\n",
            "Epoch 137/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5357 - loss: 0.7368\n",
            "Epoch 138/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7365\n",
            "Epoch 139/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7363\n",
            "Epoch 140/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7360\n",
            "Epoch 141/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7358\n",
            "Epoch 142/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7355\n",
            "Epoch 143/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7353\n",
            "Epoch 144/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5357 - loss: 0.7351\n",
            "Epoch 145/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7348\n",
            "Epoch 146/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7346\n",
            "Epoch 147/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5357 - loss: 0.7343\n",
            "Epoch 148/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5357 - loss: 0.7341\n",
            "Epoch 149/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5357 - loss: 0.7338\n",
            "Epoch 150/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5357 - loss: 0.7336\n",
            "Epoch 151/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5357 - loss: 0.7333\n",
            "Epoch 152/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7331\n",
            "Epoch 153/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7329\n",
            "Epoch 154/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7326\n",
            "Epoch 155/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7324\n",
            "Epoch 156/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7322\n",
            "Epoch 157/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7319\n",
            "Epoch 158/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7317\n",
            "Epoch 159/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7315\n",
            "Epoch 160/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5357 - loss: 0.7312\n",
            "Epoch 161/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5357 - loss: 0.7310\n",
            "Epoch 162/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7308\n",
            "Epoch 163/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7305\n",
            "Epoch 164/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5357 - loss: 0.7303\n",
            "Epoch 165/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7301\n",
            "Epoch 166/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7299\n",
            "Epoch 167/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7296\n",
            "Epoch 168/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7294\n",
            "Epoch 169/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7292\n",
            "Epoch 170/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7290\n",
            "Epoch 171/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7287\n",
            "Epoch 172/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7285\n",
            "Epoch 173/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7283\n",
            "Epoch 174/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7281\n",
            "Epoch 175/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7279\n",
            "Epoch 176/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7276\n",
            "Epoch 177/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5357 - loss: 0.7274\n",
            "Epoch 178/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7272\n",
            "Epoch 179/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7270\n",
            "Epoch 180/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7268\n",
            "Epoch 181/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7266\n",
            "Epoch 182/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5357 - loss: 0.7264\n",
            "Epoch 183/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5357 - loss: 0.7261\n",
            "Epoch 184/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7259\n",
            "Epoch 185/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5357 - loss: 0.7257\n",
            "Epoch 186/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7255\n",
            "Epoch 187/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5357 - loss: 0.7253\n",
            "Epoch 188/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7251\n",
            "Epoch 189/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7249\n",
            "Epoch 190/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7247\n",
            "Epoch 191/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7245\n",
            "Epoch 192/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7243\n",
            "Epoch 193/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7241\n",
            "Epoch 194/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7239\n",
            "Epoch 195/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7237\n",
            "Epoch 196/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7235\n",
            "Epoch 197/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7233\n",
            "Epoch 198/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5357 - loss: 0.7231\n",
            "Epoch 199/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5357 - loss: 0.7229\n",
            "Epoch 200/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5357 - loss: 0.7227\n",
            "Epoch 201/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7225\n",
            "Epoch 202/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5357 - loss: 0.7223\n",
            "Epoch 203/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5357 - loss: 0.7221\n",
            "Epoch 204/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7219\n",
            "Epoch 205/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7217\n",
            "Epoch 206/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7215\n",
            "Epoch 207/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7214\n",
            "Epoch 208/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7212\n",
            "Epoch 209/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7210\n",
            "Epoch 210/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7208\n",
            "Epoch 211/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7206\n",
            "Epoch 212/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5357 - loss: 0.7204\n",
            "Epoch 213/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7202\n",
            "Epoch 214/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5357 - loss: 0.7200\n",
            "Epoch 215/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5357 - loss: 0.7199\n",
            "Epoch 216/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7197\n",
            "Epoch 217/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7195\n",
            "Epoch 218/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5357 - loss: 0.7193\n",
            "Epoch 219/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7191\n",
            "Epoch 220/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7190\n",
            "Epoch 221/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5357 - loss: 0.7188\n",
            "Epoch 222/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5357 - loss: 0.7186\n",
            "Epoch 223/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7184\n",
            "Epoch 224/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7183\n",
            "Epoch 225/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7181\n",
            "Epoch 226/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5357 - loss: 0.7179\n",
            "Epoch 227/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5714 - loss: 0.7177\n",
            "Epoch 228/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5714 - loss: 0.7176\n",
            "Epoch 229/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5714 - loss: 0.7174\n",
            "Epoch 230/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5714 - loss: 0.7172\n",
            "Epoch 231/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5714 - loss: 0.7170\n",
            "Epoch 232/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5714 - loss: 0.7169\n",
            "Epoch 233/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5714 - loss: 0.7167\n",
            "Epoch 234/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5714 - loss: 0.7165\n",
            "Epoch 235/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5714 - loss: 0.7164\n",
            "Epoch 236/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5714 - loss: 0.7162\n",
            "Epoch 237/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5714 - loss: 0.7160\n",
            "Epoch 238/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5714 - loss: 0.7159\n",
            "Epoch 239/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5714 - loss: 0.7157\n",
            "Epoch 240/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5714 - loss: 0.7156\n",
            "Epoch 241/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5714 - loss: 0.7154\n",
            "Epoch 242/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5714 - loss: 0.7152\n",
            "Epoch 243/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5714 - loss: 0.7151\n",
            "Epoch 244/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5714 - loss: 0.7149\n",
            "Epoch 245/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5714 - loss: 0.7148\n",
            "Epoch 246/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5714 - loss: 0.7146\n",
            "Epoch 247/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5714 - loss: 0.7144\n",
            "Epoch 248/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5714 - loss: 0.7143\n",
            "Epoch 249/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5714 - loss: 0.7141\n",
            "Epoch 250/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5714 - loss: 0.7140\n",
            "Epoch 251/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5714 - loss: 0.7138\n",
            "Epoch 252/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5714 - loss: 0.7137\n",
            "Epoch 253/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5714 - loss: 0.7135\n",
            "Epoch 254/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5714 - loss: 0.7134\n",
            "Epoch 255/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5714 - loss: 0.7132\n",
            "Epoch 256/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5714 - loss: 0.7131\n",
            "Epoch 257/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5714 - loss: 0.7129\n",
            "Epoch 258/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5714 - loss: 0.7128\n",
            "Epoch 259/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5714 - loss: 0.7126\n",
            "Epoch 260/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5714 - loss: 0.7125\n",
            "Epoch 261/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5714 - loss: 0.7123\n",
            "Epoch 262/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5714 - loss: 0.7122\n",
            "Epoch 263/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5714 - loss: 0.7120\n",
            "Epoch 264/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5714 - loss: 0.7119\n",
            "Epoch 265/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5714 - loss: 0.7117\n",
            "Epoch 266/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5714 - loss: 0.7116\n",
            "Epoch 267/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5714 - loss: 0.7115\n",
            "Epoch 268/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5714 - loss: 0.7113\n",
            "Epoch 269/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5714 - loss: 0.7112\n",
            "Epoch 270/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5714 - loss: 0.7110\n",
            "Epoch 271/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5714 - loss: 0.7109\n",
            "Epoch 272/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5714 - loss: 0.7108\n",
            "Epoch 273/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5714 - loss: 0.7106\n",
            "Epoch 274/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5714 - loss: 0.7105\n",
            "Epoch 275/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5714 - loss: 0.7103\n",
            "Epoch 276/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5714 - loss: 0.7102\n",
            "Epoch 277/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5714 - loss: 0.7101\n",
            "Epoch 278/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5714 - loss: 0.7099\n",
            "Epoch 279/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5714 - loss: 0.7098\n",
            "Epoch 280/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5714 - loss: 0.7097\n",
            "Epoch 281/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5714 - loss: 0.7095\n",
            "Epoch 282/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5714 - loss: 0.7094\n",
            "Epoch 283/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.5714 - loss: 0.7093\n",
            "Epoch 284/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5714 - loss: 0.7091\n",
            "Epoch 285/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5714 - loss: 0.7090\n",
            "Epoch 286/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5714 - loss: 0.7089\n",
            "Epoch 287/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5714 - loss: 0.7088\n",
            "Epoch 288/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5714 - loss: 0.7086\n",
            "Epoch 289/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5714 - loss: 0.7085\n",
            "Epoch 290/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5714 - loss: 0.7084\n",
            "Epoch 291/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5714 - loss: 0.7083\n",
            "Epoch 292/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5714 - loss: 0.7081\n",
            "Epoch 293/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5714 - loss: 0.7080\n",
            "Epoch 294/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5714 - loss: 0.7079\n",
            "Epoch 295/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5714 - loss: 0.7078\n",
            "Epoch 296/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5714 - loss: 0.7076\n",
            "Epoch 297/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5714 - loss: 0.7075\n",
            "Epoch 298/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5714 - loss: 0.7074\n",
            "Epoch 299/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5714 - loss: 0.7073\n",
            "Epoch 300/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5714 - loss: 0.7072\n",
            "Epoch 301/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5714 - loss: 0.7070\n",
            "Epoch 302/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5714 - loss: 0.7069\n",
            "Epoch 303/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5714 - loss: 0.7068\n",
            "Epoch 304/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5714 - loss: 0.7067\n",
            "Epoch 305/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7066\n",
            "Epoch 306/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5357 - loss: 0.7064\n",
            "Epoch 307/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7063\n",
            "Epoch 308/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7062\n",
            "Epoch 309/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7061\n",
            "Epoch 310/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5357 - loss: 0.7060\n",
            "Epoch 311/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5357 - loss: 0.7059\n",
            "Epoch 312/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5357 - loss: 0.7058\n",
            "Epoch 313/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5357 - loss: 0.7057\n",
            "Epoch 314/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5357 - loss: 0.7055\n",
            "Epoch 315/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5357 - loss: 0.7054\n",
            "Epoch 316/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5357 - loss: 0.7053\n",
            "Epoch 317/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5357 - loss: 0.7052\n",
            "Epoch 318/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5357 - loss: 0.7051\n",
            "Epoch 319/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5357 - loss: 0.7050\n",
            "Epoch 320/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5357 - loss: 0.7049\n",
            "Epoch 321/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5357 - loss: 0.7048\n",
            "Epoch 322/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5357 - loss: 0.7047\n",
            "Epoch 323/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5357 - loss: 0.7046\n",
            "Epoch 324/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5357 - loss: 0.7045\n",
            "Epoch 325/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5357 - loss: 0.7044\n",
            "Epoch 326/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7043\n",
            "Epoch 327/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7042\n",
            "Epoch 328/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5357 - loss: 0.7041\n",
            "Epoch 329/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5357 - loss: 0.7040\n",
            "Epoch 330/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5357 - loss: 0.7039\n",
            "Epoch 331/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5357 - loss: 0.7038\n",
            "Epoch 332/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5357 - loss: 0.7037\n",
            "Epoch 333/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5357 - loss: 0.7036\n",
            "Epoch 334/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5357 - loss: 0.7035\n",
            "Epoch 335/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5357 - loss: 0.7034\n",
            "Epoch 336/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5357 - loss: 0.7033\n",
            "Epoch 337/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5357 - loss: 0.7032\n",
            "Epoch 338/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5357 - loss: 0.7031\n",
            "Epoch 339/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5357 - loss: 0.7030\n",
            "Epoch 340/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5357 - loss: 0.7029\n",
            "Epoch 341/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4643 - loss: 0.7028\n",
            "Epoch 342/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4643 - loss: 0.7027\n",
            "Epoch 343/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4643 - loss: 0.7026\n",
            "Epoch 344/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4643 - loss: 0.7025\n",
            "Epoch 345/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4643 - loss: 0.7024\n",
            "Epoch 346/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4643 - loss: 0.7023\n",
            "Epoch 347/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4643 - loss: 0.7022\n",
            "Epoch 348/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4643 - loss: 0.7021\n",
            "Epoch 349/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4643 - loss: 0.7020\n",
            "Epoch 350/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4643 - loss: 0.7020\n",
            "Epoch 351/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4643 - loss: 0.7019\n",
            "Epoch 352/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4643 - loss: 0.7018\n",
            "Epoch 353/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4643 - loss: 0.7017\n",
            "Epoch 354/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4643 - loss: 0.7016\n",
            "Epoch 355/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4643 - loss: 0.7015\n",
            "Epoch 356/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4643 - loss: 0.7014\n",
            "Epoch 357/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4643 - loss: 0.7013\n",
            "Epoch 358/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4643 - loss: 0.7013\n",
            "Epoch 359/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.7012\n",
            "Epoch 360/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.7011\n",
            "Epoch 361/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.7010\n",
            "Epoch 362/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.7009\n",
            "Epoch 363/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.7008\n",
            "Epoch 364/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.7007\n",
            "Epoch 365/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.7007\n",
            "Epoch 366/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.7006\n",
            "Epoch 367/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.7005\n",
            "Epoch 368/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.7004\n",
            "Epoch 369/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.7003\n",
            "Epoch 370/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.7003\n",
            "Epoch 371/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.7002\n",
            "Epoch 372/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.7001\n",
            "Epoch 373/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5000 - loss: 0.7000\n",
            "Epoch 374/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.7000\n",
            "Epoch 375/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6999\n",
            "Epoch 376/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6998\n",
            "Epoch 377/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6997\n",
            "Epoch 378/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6996\n",
            "Epoch 379/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6996\n",
            "Epoch 380/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6995\n",
            "Epoch 381/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6994\n",
            "Epoch 382/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6993\n",
            "Epoch 383/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.6993\n",
            "Epoch 384/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6992\n",
            "Epoch 385/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6991\n",
            "Epoch 386/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6991\n",
            "Epoch 387/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6990\n",
            "Epoch 388/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6989\n",
            "Epoch 389/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 0.6988\n",
            "Epoch 390/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6988\n",
            "Epoch 391/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6987\n",
            "Epoch 392/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6986\n",
            "Epoch 393/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6986\n",
            "Epoch 394/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6985\n",
            "Epoch 395/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6984\n",
            "Epoch 396/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6984\n",
            "Epoch 397/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6983\n",
            "Epoch 398/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6982\n",
            "Epoch 399/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5000 - loss: 0.6982\n",
            "Epoch 400/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6981\n",
            "Epoch 401/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6980\n",
            "Epoch 402/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6980\n",
            "Epoch 403/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6979\n",
            "Epoch 404/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6978\n",
            "Epoch 405/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6978\n",
            "Epoch 406/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6977\n",
            "Epoch 407/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6976\n",
            "Epoch 408/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6976\n",
            "Epoch 409/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6975\n",
            "Epoch 410/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6975\n",
            "Epoch 411/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6974\n",
            "Epoch 412/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6973\n",
            "Epoch 413/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6973\n",
            "Epoch 414/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6972\n",
            "Epoch 415/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.6972\n",
            "Epoch 416/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6971\n",
            "Epoch 417/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6970\n",
            "Epoch 418/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6970\n",
            "Epoch 419/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6969\n",
            "Epoch 420/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6969\n",
            "Epoch 421/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6968\n",
            "Epoch 422/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6968\n",
            "Epoch 423/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6967\n",
            "Epoch 424/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6966\n",
            "Epoch 425/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6966\n",
            "Epoch 426/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6965\n",
            "Epoch 427/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6965\n",
            "Epoch 428/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6964\n",
            "Epoch 429/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 0.6964\n",
            "Epoch 430/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6963\n",
            "Epoch 431/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5000 - loss: 0.6963\n",
            "Epoch 432/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6962\n",
            "Epoch 433/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6961\n",
            "Epoch 434/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6961\n",
            "Epoch 435/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6960\n",
            "Epoch 436/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6960\n",
            "Epoch 437/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6959\n",
            "Epoch 438/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6959\n",
            "Epoch 439/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6958\n",
            "Epoch 440/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6958\n",
            "Epoch 441/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6957\n",
            "Epoch 442/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6957\n",
            "Epoch 443/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6956\n",
            "Epoch 444/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6956\n",
            "Epoch 445/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6955\n",
            "Epoch 446/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5000 - loss: 0.6955\n",
            "Epoch 447/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6954\n",
            "Epoch 448/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6954\n",
            "Epoch 449/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6954\n",
            "Epoch 450/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 451/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 452/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6952\n",
            "Epoch 453/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6952\n",
            "Epoch 454/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 455/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 456/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 457/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.6950\n",
            "Epoch 458/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 459/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 460/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 461/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 462/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 463/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 464/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Epoch 465/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 466/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 467/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 468/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 469/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 470/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 471/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 472/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 473/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 474/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 475/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 476/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 477/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 478/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6941\n",
            "Epoch 479/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.5000 - loss: 0.6941\n",
            "Epoch 480/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5000 - loss: 0.6940\n",
            "Epoch 481/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5000 - loss: 0.6940\n",
            "Epoch 482/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5000 - loss: 0.6940\n",
            "Epoch 483/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.5000 - loss: 0.6939\n",
            "Epoch 484/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5000 - loss: 0.6939\n",
            "Epoch 485/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5000 - loss: 0.6939\n",
            "Epoch 486/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5000 - loss: 0.6938\n",
            "Epoch 487/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6938\n",
            "Epoch 488/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6937\n",
            "Epoch 489/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6937\n",
            "Epoch 490/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5000 - loss: 0.6937\n",
            "Epoch 491/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6936\n",
            "Epoch 492/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6936\n",
            "Epoch 493/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5000 - loss: 0.6936\n",
            "Epoch 494/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6935\n",
            "Epoch 495/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6935\n",
            "Epoch 496/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5000 - loss: 0.6935\n",
            "Epoch 497/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 498/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 499/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 500/500\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5000 - loss: 0.6933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fdd1552a2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AtrvvLfp00T",
        "outputId": "ffd1e21a-76d8-4856-f8ae-adcbcd9edeb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7143 - loss: 0.5859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5858982801437378, 0.7142857313156128]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ot82YBrGqYRJ",
        "outputId": "914555c3-abad-46c4-da1e-38f126419b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Age  Affordibility\n",
              "17  0.60              1\n",
              "33  0.82              1\n",
              "32  0.80              0\n",
              "10  0.24              0\n",
              "16  0.49              1\n",
              "21  0.56              1\n",
              "27  0.34              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85a976ed-c707-4135-a321-21352cf9b010\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Affordibility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.60</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.56</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.34</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85a976ed-c707-4135-a321-21352cf9b010')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85a976ed-c707-4135-a321-21352cf9b010 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85a976ed-c707-4135-a321-21352cf9b010');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_test_scaled",
              "summary": "{\n  \"name\": \"x_test_scaled\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2167179426505029,\n        \"min\": 0.24,\n        \"max\": 0.82,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.6,\n          0.82,\n          0.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Affordibility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "QRSk6WRSq6jB",
        "outputId": "b90959da-1c8f-4a39-ab74-2c60690e68a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17    1\n",
              "33    1\n",
              "32    0\n",
              "10    0\n",
              "16    0\n",
              "21    1\n",
              "27    1\n",
              "Name: Bought_Insurance, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bought_Insurance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_test_scaled)\n",
        "#we will match the prediction with x_test_scaled\n",
        "#As our model's accuracy is not that close to 1, it's assumption may be wrong\n",
        "#lets compare\n",
        "#for age = 0.80, affordibility = 1, as our prediction >  0.5, our model predicted correctly as our datset's bought insurance is 1\n",
        "#but age = 0.49, affordibility = 1, as our prediction >  0.5, our model predicted wrong as our datset's bought insurance is 0 --> meaning it is saying person will buy insurancek\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij0Y2NzHp-HA",
        "outputId": "3ebae8fa-8889-4edb-96df-5322acff37e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6603124 ],\n",
              "       [0.691542  ],\n",
              "       [0.5428289 ],\n",
              "       [0.45230153],\n",
              "       [0.64413595],\n",
              "       [0.6544709 ],\n",
              "       [0.62154216]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coef , intercept = model.get_weights()\n",
        "coef, intercept\n",
        "#here, w1 = 0.64841515, w2 = 0.6226333, b= -0.3469955"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDaOtWB0aKk3",
        "outputId": "123a9b79-e5f6-4b69-98f8-e6b5045e5bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.64841515],\n",
              "        [0.6226333 ]], dtype=float32),\n",
              " array([-0.3469955], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building without tensorflow from scratch**"
      ],
      "metadata": {
        "id": "It1m3FLzsOfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / ( 1+ math.exp(-x))"
      ],
      "metadata": {
        "id": "bLKIrE3GbwLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_func(age, affordibility):#calculating z = w1*x1 + w2* x2 + b\n",
        "   weighted_sum = coef[0]*age + coef[1]*affordibility + intercept\n",
        "   return sigmoid(weighted_sum)"
      ],
      "metadata": {
        "id": "rlLMyxdDsc9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_func(0.60, 1)#it matches with our model.prediction's 1st utput"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73rvEy9ws-9k",
        "outputId": "6df847e8-1437-4197-c699-8dcb2f9acace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-002f9ef5df6f>:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  return 1 / ( 1+ math.exp(-x))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6603124523954439"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_predicted):#made binary cross entropy\n",
        "  epsilon = 1e-15\n",
        "  y_predicted_new = [max(i, epsilon) for i in y_predicted]\n",
        "  y_predicted_new = [min(i, 1-epsilon) for i in y_predicted_new]\n",
        "  y_predicted_new = np.array(y_predicted_new)\n",
        "  return -(np.mean(y_true*np.log(y_predicted_new) + (1-y_true) * np.log(1 - y_predicted_new)))"
      ],
      "metadata": {
        "id": "Gfq0x5dcQ-Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_numpy(x):\n",
        "  return 1 / ( 1+ np.exp(-x))\n",
        "#at the gradient_descent function and the global variables, it appears that age and affordibility are being passed as Pandas Series\n",
        "#the sigmoid function is defined to use math.exp, which expects a single numerical value (like an integer or float), not a Pandas Serie\n",
        "#thus if we run sigmoid, it will give error"
      ],
      "metadata": {
        "id": "gm8HRDWv4Lo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(age, affordibility, y_true, epochs):#WHERE features are many, we will take x\n",
        "    #when features are many, we will take\n",
        "    #num_features = x.shape[1]\n",
        "    #w = np.ones(num_features) if num_features = 4, this line will give [1,1,1,1]\n",
        "    #sample_len = x.shape[0]\n",
        "\n",
        "    w1 = w2 = 1\n",
        "    bias = 0\n",
        "    rate = 0.5#learning rate\n",
        "    sample_len = len(age)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      weighted_sum = w1 *age + w2*affordibility + bias\n",
        "      y_predicted = sigmoid_numpy(weighted_sum)\n",
        "\n",
        "      loss = log_loss(y_true, y_predicted)\n",
        "\n",
        "      derivative_w1 = (1/sample_len) * np.dot(np.transpose(age), (y_predicted - y_true))\n",
        "      derivative_w2 = (1/sample_len) * np.dot(np.transpose(affordibility), (y_predicted - y_true))\n",
        "      derivative_bias = np.mean(y_predicted - y_true)\n",
        "\n",
        "      w1 = w1 - rate* derivative_w1\n",
        "      w2 = w2 - rate* derivative_w2\n",
        "      bias = bias - rate* derivative_bias\n",
        "\n",
        "      print(f\"Epoch:{i}, w1 : {w1}, w2:{w2}, Bias:{bias}, loss:{loss}\")\n",
        "\n",
        "    return w1, w2, bias\n",
        "\n"
      ],
      "metadata": {
        "id": "Id5G7ojrt-xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(x_train_scaled[\"Age\"], x_train_scaled[\"Affordibility\"], y_train, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fkzJ5KnqukUk",
        "outputId": "16159a4e-505b-45ba-f3bb-9e179376105c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0, w1 : 0.9547718165442592, w2:0.9408295195534853, Bias:-0.09110665735771768, loss:0.7808026615418449\n",
            "Epoch:1, w1 : 0.9161337154378755, w2:0.8885521463695576, Bias:-0.16856946189722624, loss:0.7550340778716349\n",
            "Epoch:2, w1 : 0.8834710360721807, w2:0.8427719613501229, Bias:-0.2336593373208486, loss:0.7360960830049563\n",
            "Epoch:3, w1 : 0.856101324999775, w2:0.8029361469503108, Bias:-0.28778778602452404, loss:0.7224473960757584\n",
            "Epoch:4, w1 : 0.8333310428397971, w2:0.768409322894624, Bias:-0.3323891210821248, loss:0.7127638979538975\n",
            "Epoch:5, w1 : 0.8144965539599085, w2:0.7385350569812978, Bias:-0.36883541613685017, loss:0.7059754961340622\n",
            "Epoch:6, w1 : 0.7989893253050251, w2:0.7126794811712769, Bias:-0.39838434254620836, loss:0.7012570759815172\n",
            "Epoch:7, w1 : 0.7862682282696151, w2:0.6902578733368477, Bias:-0.4221538267666259, loss:0.6979948197851018\n",
            "Epoch:8, w1 : 0.7758627051289785, w2:0.6707478229129349, Bias:-0.4411156583723295, loss:0.6957443299659516\n",
            "Epoch:9, w1 : 0.7673702060120836, w2:0.6536931056501973, Bias:-0.45610094367197207, loss:0.6941903816253351\n",
            "Epoch:10, w1 : 0.7604504876260623, w2:0.638701790185872, Bias:-0.467812016833409, loss:0.6931127832921994\n",
            "Epoch:11, w1 : 0.7548185339362682, w2:0.6254411731590142, Bias:-0.47683716091789136, loss:0.6923594859562072\n",
            "Epoch:12, w1 : 0.7502371910824754, w2:0.6136312796330334, Bias:-0.4836658839243487, loss:0.6918263947009821\n",
            "Epoch:13, w1 : 0.7465101351580845, w2:0.6030380025411137, Bias:-0.4887034786956043, loss:0.6914426998091978\n",
            "Epoch:14, w1 : 0.7434754821581685, w2:0.593466493611631, Bias:-0.4922842355596593, loss:0.6911604600671363\n",
            "Epoch:15, w1 : 0.7410001601066394, w2:0.5847551188022705, Bias:-0.4946830667234869, loss:0.6909473263440711\n",
            "Epoch:16, w1 : 0.7389750546439388, w2:0.5767701074064088, Bias:-0.49612552452778325, loss:0.6907815193950787\n",
            "Epoch:17, w1 : 0.7373108816980309, w2:0.5694009171483357, Bias:-0.49679631327009544, loss:0.6906483941877134\n",
            "Epoch:18, w1 : 0.7359347141333553, w2:0.5625562796725309, Bias:-0.49684644825741575, loss:0.6905381051700219\n",
            "Epoch:19, w1 : 0.734787080468207, w2:0.556160862832998, Bias:-0.4963992329781093, loss:0.6904440276870509\n",
            "Epoch:20, w1 : 0.7338195547910678, w2:0.550152475790162, Bias:-0.4955552224485106, loss:0.6903616947772394\n",
            "Epoch:21, w1 : 0.7329927630267064, w2:0.544479742411066, Bias:-0.49439632788481946, loss:0.6902880832240842\n",
            "Epoch:22, w1 : 0.7322747388633681, w2:0.5391001731369067, Bias:-0.4929892006873762, loss:0.6902211352452321\n",
            "Epoch:23, w1 : 0.7316395713544711, w2:0.5339785725328309, Bias:-0.49138801555744166, loss:0.6901594386215706\n",
            "Epoch:24, w1 : 0.7310662945988021, w2:0.529085727557296, Bias:-0.48963675512223187, loss:0.6901020130760163\n",
            "Epoch:25, w1 : 0.7305379775676557, w2:0.5243973292952242, Bias:-0.4877710825519849, loss:0.6900481677535515\n",
            "Epoch:26, w1 : 0.7300409789226323, w2:0.5198930880379666, Bias:-0.48581987463125703, loss:0.6899974062021306\n",
            "Epoch:27, w1 : 0.7295643375301354, w2:0.5155560079659378, Bias:-0.4838064756316132, loss:0.6899493630454908\n",
            "Epoch:28, w1 : 0.7290992743769665, w2:0.5113717932440198, Bias:-0.48174972201456323, loss:0.6899037617780307\n",
            "Epoch:29, w1 : 0.7286387858087784, w2:0.5073283621016659, Bias:-0.47966477929495827, loss:0.6898603866255346\n",
            "Epoch:30, w1 : 0.7281773115444142, w2:0.5034154495045462, Bias:-0.47756382511649403, loss:0.6898190637669169\n",
            "Epoch:31, w1 : 0.7277104638590804, w2:0.49962428241431295, Bias:-0.47545660653457167, loss:0.689779648783147\n",
            "Epoch:32, w1 : 0.7272348067662554, w2:0.4959473144625068, Bias:-0.47335089448369694, loss:0.6897420182476404\n",
            "Epoch:33, w1 : 0.7267476760414954, w2:0.4923780092148422, Bias:-0.47125285426246183, loss:0.6897060640709027\n",
            "Epoch:34, w1 : 0.7262470325901454, w2:0.488910663146862, Bias:-0.46916734745552413, loss:0.6896716896772797\n",
            "Epoch:35, w1 : 0.725731343024939, w2:0.48554026105641895, Bias:-0.46709817790581054, loss:0.6896388074010872\n",
            "Epoch:36, w1 : 0.725199482439128, w2:0.4822623579590588, Bias:-0.4650482920470714, loss:0.6896073366951031\n",
            "Epoch:37, w1 : 0.7246506552786461, w2:0.47907298259732184, Bias:-0.4630199420191879, loss:0.6895772028811055\n",
            "Epoch:38, w1 : 0.724084330968423, w2:0.4759685585849649, Bias:-0.46101481844300796, loss:0.6895483362629461\n",
            "Epoch:39, w1 : 0.7235001915628911, w2:0.4729458399362665, Bias:-0.4590341584670744, loss:0.6895206714829248\n",
            "Epoch:40, w1 : 0.7228980891934527, w2:0.47000185832738456, Bias:-0.4570788336649916, loss:0.6894941470422519\n",
            "Epoch:41, w1 : 0.7222780114964066, w2:0.4671338799248064, Bias:-0.4551494215177339, loss:0.6894687049329459\n",
            "Epoch:42, w1 : 0.7216400535402522, w2:0.4643393700148081, Bias:-0.45324626352565855, loss:0.6894442903461181\n",
            "Epoch:43, w1 : 0.7209843950450575, w2:0.4616159639936349, Bias:-0.451369512432171, loss:0.689420851433302\n",
            "Epoch:44, w1 : 0.7203112819099705, w2:0.4589614435440955, Bias:-0.4495191705817825, loss:0.6893983391052275\n",
            "Epoch:45, w1 : 0.7196210112471593, w2:0.4563737170413161, Bias:-0.44769512106074083, loss:0.6893767068575976\n",
            "Epoch:46, w1 : 0.7189139192690538, w2:0.4538508034074736, Bias:-0.4458971529629854, loss:0.6893559106168309\n",
            "Epoch:47, w1 : 0.7181903714968931, w2:0.4513908187797359, Bias:-0.44412498187517835, loss:0.6893359086010115\n",
            "Epoch:48, w1 : 0.7174507548573161, w2:0.44899196547337866, Bias:-0.4423782664716131, loss:0.6893166611927911\n",
            "Epoch:49, w1 : 0.7166954713141926, w2:0.446652522818027, Bias:-0.4406566219444083, loss:0.6892981308219918\n",
            "Epoch:50, w1 : 0.7159249327484499, w2:0.44437083952319184, Bias:-0.43895963085964235, loss:0.6892802818563305\n",
            "Epoch:51, w1 : 0.7151395568520535, w2:0.4421453272930104, Bias:-0.43728685192030003, loss:0.6892630804991339\n",
            "Epoch:52, w1 : 0.7143397638458059, w2:0.4399744554620299, Bias:-0.4356378270274836, loss:0.6892464946932105\n",
            "Epoch:53, w1 : 0.7135259738660527, w2:0.43785674646617856, Bias:-0.4340120869585099, loss:0.689230494030255\n",
            "Epoch:54, w1 : 0.7126986048942394, w2:0.4357907719975248, Bias:-0.4324091559212101, loss:0.6892150496652908\n",
            "Epoch:55, w1 : 0.7118580711267526, w2:0.43377514971948855, Bias:-0.4308285551954544, loss:0.6892001342357617\n",
            "Epoch:56, w1 : 0.7110047817016042, w2:0.4318085404420221, Bias:-0.42926980603360804, loss:0.6891857217849419\n",
            "Epoch:57, w1 : 0.7101391397140914, w2:0.42988964567488835, Bias:-0.42773243195961635, loss:0.6891717876893877\n",
            "Epoch:58, w1 : 0.7092615414662334, w2:0.42801720549231487, Bias:-0.4262159605803601, loss:0.689158308590182\n",
            "Epoch:59, w1 : 0.7083723759051066, w2:0.4261899966546402, Bias:-0.42471992500171635, loss:0.6891452623277535\n",
            "Epoch:60, w1 : 0.70747202421359, w2:0.42440683094261167, Bias:-0.4232438649244988, loss:0.6891326278800732\n",
            "Epoch:61, w1 : 0.70656085952387, w2:0.4226665536681709, Bias:-0.42178732748140463, loss:0.689120385304042\n",
            "Epoch:62, w1 : 0.7056392467296073, w2:0.4209680423322189, Bias:-0.42034986786466544, loss:0.6891085156799007\n",
            "Epoch:63, w1 : 0.7047075423771948, w2:0.41931020540527253, Bias:-0.4189310497847981, loss:0.6890970010585039\n",
            "Epoch:64, w1 : 0.7037660946202132, w2:0.41769198121133355, Bias:-0.4175304457932856, loss:0.689085824411304\n",
            "Epoch:65, w1 : 0.7028152432241861, w2:0.4161123368988844, Bias:-0.41614763749586026, loss:0.689074969582914\n",
            "Epoch:66, w1 : 0.7018553196111672, w2:0.41457026748584636, Bias:-0.41478221567805545, loss:0.6890644212461039\n",
            "Epoch:67, w1 : 0.7008866469356767, w2:0.413064794967718, Bias:-0.4134337803606165, loss:0.6890541648591176\n",
            "Epoch:68, w1 : 0.6999095401851106, w2:0.4115949674800481, Bias:-0.4121019407990506, loss:0.6890441866251803\n",
            "Epoch:69, w1 : 0.6989243062990578, w2:0.4101598585079769, Bias:-0.41078631543889865, loss:0.6890344734540929\n",
            "Epoch:70, w1 : 0.6979312443030218, w2:0.40875856613686384, Bias:-0.4094865318361231, loss:0.6890250129257993\n",
            "Epoch:71, w1 : 0.6969306454529132, w2:0.4073902123390679, Bias:-0.40820222655022265, loss:0.689015793255832\n",
            "Epoch:72, w1 : 0.6959227933873762, w2:0.4060539422928, Bias:-0.406933045016237, loss:0.6890068032625313\n",
            "Epoch:73, w1 : 0.6949079642855893, w2:0.4047489237296618, Bias:-0.4056786414006278, loss:0.688998032335958\n",
            "Epoch:74, w1 : 0.6938864270286408, w2:0.4034743463080533, Bias:-0.4044386784450635, loss:0.6889894704084023\n",
            "Epoch:75, w1 : 0.6928584433629571, w2:0.4022294210100939, Bias:-0.40321282730136, loss:0.6889811079264134\n",
            "Epoch:76, w1 : 0.6918242680645699, w2:0.40101337956007993, Bias:-0.40200076736019585, loss:0.6889729358242705\n",
            "Epoch:77, w1 : 0.6907841491032526, w2:0.39982547386280953, Bias:-0.40080218607570806, loss:0.6889649454988193\n",
            "Epoch:78, w1 : 0.6897383278057625, w2:0.39866497546035945, Bias:-0.39961677878765706, loss:0.6889571287856064\n",
            "Epoch:79, w1 : 0.6886870390175835, w2:0.3975311750061038, Bias:-0.3984442485425121, loss:0.6889494779362441\n",
            "Epoch:80, w1 : 0.6876305112627006, w2:0.39642338175493497, Bias:-0.3972843059145332, loss:0.6889419855969398\n",
            "Epoch:81, w1 : 0.6865689669010413, w2:0.39534092306878577, Bias:-0.396136668827702, loss:0.6889346447881373\n",
            "Epoch:82, w1 : 0.6855026222833088, w2:0.3942831439366662, Bias:-0.39500106237917526, loss:0.6889274488852022\n",
            "Epoch:83, w1 : 0.6844316879029977, w2:0.39324940650852297, Bias:-0.3938772186647863, loss:0.688920391600108\n",
            "Epoch:84, w1 : 0.6833563685454433, w2:0.39223908964230714, Bias:-0.3927648766070027, loss:0.688913466964065\n",
            "Epoch:85, w1 : 0.6822768634337992, w2:0.39125158846370056, Bias:-0.3916637817856517, loss:0.6889066693110462\n",
            "Epoch:86, w1 : 0.6811933663718734, w2:0.39028631393800545, Bias:-0.39057368627164785, loss:0.6888999932621639\n",
            "Epoch:87, w1 : 0.680106065883785, w2:0.3893426924537454, Bias:-0.3894943484638945, loss:0.6888934337108495\n",
            "Epoch:88, w1 : 0.6790151453504241, w2:0.3884201654175657, Bias:-0.3884255329294808, loss:0.6888869858088046\n",
            "Epoch:89, w1 : 0.6779207831427192, w2:0.38751818886005024, Bias:-0.38736701024725406, loss:0.6888806449526691\n",
            "Epoch:90, w1 : 0.6768231527517277, w2:0.38663623305210154, Bias:-0.38631855685481725, loss:0.6888744067713862\n",
            "Epoch:91, w1 : 0.6757224229155795, w2:0.3857737821315515, Bias:-0.3852799548989723, loss:0.6888682671142133\n",
            "Epoch:92, w1 : 0.6746187577433118, w2:0.3849303337396915, Bias:-0.3842509920896118, loss:0.6888622220393553\n",
            "Epoch:93, w1 : 0.6735123168356397, w2:0.38410539866742693, Bias:-0.38323146155704313, loss:0.6888562678031847\n",
            "Epoch:94, w1 : 0.6724032554027131, w2:0.3832985005107769, Bias:-0.3822211617127179, loss:0.6888504008500167\n",
            "Epoch:95, w1 : 0.6712917243789144, w2:0.3825091753354518, Bias:-0.3812198961133277, loss:0.688844617802416\n",
            "Epoch:96, w1 : 0.670177870534755, w2:0.38173697135025453, Bias:-0.38022747332822004, loss:0.6888389154520008\n",
            "Epoch:97, w1 : 0.6690618365859287, w2:0.3809814485890603, Bias:-0.3792437068100831, loss:0.688833290750724\n",
            "Epoch:98, w1 : 0.667943761299583, w2:0.3802421786011403, Bias:-0.3782684147688414, loss:0.688827740802605\n",
            "Epoch:99, w1 : 0.6668237795978712, w2:0.3795187441496029, Bias:-0.3773014200487023, loss:0.6888222628558873\n",
            "Epoch:100, w1 : 0.665702022658845, w2:0.37881073891773326, Bias:-0.3763425500082921, loss:0.688816854295603\n",
            "Epoch:101, w1 : 0.664578618014751, w2:0.3781177672230204, Bias:-0.37539163640381507, loss:0.6888115126365209\n",
            "Epoch:102, w1 : 0.6634536896477916, w2:0.37743944373866717, Bias:-0.37444851527517287, loss:0.6888062355164594\n",
            "Epoch:103, w1 : 0.662327358083412, w2:0.37677539322238457, Bias:-0.3735130268349764, loss:0.6888010206899453\n",
            "Epoch:104, w1 : 0.6611997404811727, w2:0.3761252502522782, Bias:-0.3725850153603857, loss:0.6887958660221989\n",
            "Epoch:105, w1 : 0.6600709507232674, w2:0.37548865896964023, Bias:-0.3716643290877117, loss:0.688790769483432\n",
            "Epoch:106, w1 : 0.6589410995007443, w2:0.3748652728284655, Bias:-0.37075082010971505, loss:0.6887857291434404\n",
            "Epoch:107, w1 : 0.6578102943974888, w2:0.37425475435151556, Bias:-0.3698443442755372, loss:0.6887807431664749\n",
            "Epoch:108, w1 : 0.6566786399720231, w2:0.3736567748927592, Bias:-0.36894476109320046, loss:0.688775809806378\n",
            "Epoch:109, w1 : 0.6555462378371778, w2:0.37307101440602275, Bias:-0.36805193363461464, loss:0.6887709274019731\n",
            "Epoch:110, w1 : 0.6544131867376906, w2:0.3724971612196882, Bias:-0.36716572844302814, loss:0.6887660943726904\n",
            "Epoch:111, w1 : 0.6532795826257831, w2:0.37193491181728106, Bias:-0.3662860154428635, loss:0.688761309214421\n",
            "Epoch:112, w1 : 0.6521455187347696, w2:0.3713839706237948, Bias:-0.3654126678518781, loss:0.6887565704955829\n",
            "Epoch:113, w1 : 0.6510110856507451, w2:0.3708440497976016, Bias:-0.36454556209559164, loss:0.6887518768533932\n",
            "Epoch:114, w1 : 0.6498763713824053, w2:0.3703148690278046, Bias:-0.3636845777239238, loss:0.6887472269903311\n",
            "Epoch:115, w1 : 0.6487414614290442, w2:0.36979615533688925, Bias:-0.36282959732998654, loss:0.6887426196707848\n",
            "Epoch:116, w1 : 0.6476064388467769, w2:0.36928764288853627, Bias:-0.3619805064709761, loss:0.6887380537178712\n",
            "Epoch:117, w1 : 0.6464713843130337, w2:0.3687890728004609, Bias:-0.36113719359111257, loss:0.6887335280104219\n",
            "Epoch:118, w1 : 0.6453363761893697, w2:0.3683001929621485, Bias:-0.3602995499465737, loss:0.6887290414801204\n",
            "Epoch:119, w1 : 0.6442014905826334, w2:0.3678207578573581, Bias:-0.35946746953237385, loss:0.688724593108795\n",
            "Epoch:120, w1 : 0.6430668014045378, w2:0.36735052839127025, Bias:-0.35864084901113713, loss:0.6887201819258434\n",
            "Epoch:121, w1 : 0.6419323804296732, w2:0.36688927172215735, Bias:-0.35781958764371724, loss:0.6887158070057978\n",
            "Epoch:122, w1 : 0.6407982973520046, w2:0.3664367610974598, Bias:-0.3570035872216167, loss:0.6887114674660096\n",
            "Epoch:123, w1 : 0.639664619839891, w2:0.3659927756941518, Bias:-0.35619275200115924, loss:0.6887071624644591\n",
            "Epoch:124, w1 : 0.6385314135896661, w2:0.3655571004632857, Bias:-0.3553869886393709, loss:0.6887028911976757\n",
            "Epoch:125, w1 : 0.6373987423778177, w2:0.36512952597860615, Bias:-0.35458620613152536, loss:0.6886986528987656\n",
            "Epoch:126, w1 : 0.6362666681118008, w2:0.3647098482891269, Bias:-0.35379031575031167, loss:0.6886944468355427\n",
            "Epoch:127, w1 : 0.6351352508795224, w2:0.364297868775568, Bias:-0.352999230986582, loss:0.6886902723087559\n",
            "Epoch:128, w1 : 0.6340045489975302, w2:0.36389339401055215, Bias:-0.352212867491639, loss:0.6886861286504072\n",
            "Epoch:129, w1 : 0.6328746190579403, w2:0.36349623562246164, Bias:-0.35143114302102385, loss:0.6886820152221579\n",
            "Epoch:130, w1 : 0.6317455159741356, w2:0.36310621016286154, Bias:-0.3506539773797651, loss:0.6886779314138167\n",
            "Epoch:131, w1 : 0.6306172930252688, w2:0.36272313897739483, Bias:-0.34988129236905186, loss:0.6886738766419055\n",
            "Epoch:132, w1 : 0.6294900018995984, w2:0.36234684808005946, Bias:-0.34911301173429404, loss:0.6886698503483012\n",
            "Epoch:133, w1 : 0.6283636927366906, w2:0.3619771680307788, Bias:-0.3483490611145341, loss:0.6886658519989444\n",
            "Epoch:134, w1 : 0.6272384141685153, w2:0.36161393381617957, Bias:-0.3475893679931753, loss:0.6886618810826189\n",
            "Epoch:135, w1 : 0.6261142133594657, w2:0.3612569847334935, Bias:-0.3468338616499926, loss:0.6886579371097913\n",
            "Epoch:136, w1 : 0.6249911360453281, w2:0.3609061642775009, Bias:-0.3460824731143929, loss:0.6886540196115118\n",
            "Epoch:137, w1 : 0.6238692265712316, w2:0.3605613200304366, Bias:-0.3453351351198929, loss:0.6886501281383711\n",
            "Epoch:138, w1 : 0.6227485279286025, w2:0.3602223035547816, Bias:-0.3445917820597822, loss:0.6886462622595136\n",
            "Epoch:139, w1 : 0.62162908179115, w2:0.3598889702888634, Bias:-0.34385234994394176, loss:0.6886424215616972\n",
            "Epoch:140, w1 : 0.6205109285499083, w2:0.3595611794451937, Bias:-0.3431167763567877, loss:0.6886386056484063\n",
            "Epoch:141, w1 : 0.6193941073473602, w2:0.35923879391146996, Bias:-0.3423850004163108, loss:0.6886348141390072\n",
            "Epoch:142, w1 : 0.6182786561106655, w2:0.35892168015417203, Bias:-0.34165696273418406, loss:0.6886310466679498\n",
            "Epoch:143, w1 : 0.6171646115840175, w2:0.35860970812468645, Bias:-0.3409326053769101, loss:0.6886273028840085\n",
            "Epoch:144, w1 : 0.6160520093601519, w2:0.35830275116789134, Bias:-0.340211871827982, loss:0.6886235824495632\n",
            "Epoch:145, w1 : 0.6149408839110277, w2:0.3580006859331378, Bias:-0.3394947069510305, loss:0.6886198850399179\n",
            "Epoch:146, w1 : 0.6138312686177042, w2:0.3577033922875657, Bias:-0.33878105695393296, loss:0.688616210342653\n",
            "Epoch:147, w1 : 0.6127231957994331, w2:0.357410753231692, Bias:-0.33807086935385827, loss:0.6886125580570129\n",
            "Epoch:148, w1 : 0.6116166967419883, w2:0.35712265481721267, Bias:-0.33736409294322417, loss:0.6886089278933241\n",
            "Epoch:149, w1 : 0.6105118017252505, w2:0.35683898606695963, Bias:-0.3366606777565426, loss:0.6886053195724431\n",
            "Epoch:150, w1 : 0.6094085400500697, w2:0.3565596388969574, Bias:-0.3359605750381307, loss:0.6886017328252342\n",
            "Epoch:151, w1 : 0.6083069400644204, w2:0.3562845080405233, Bias:-0.3352637372106643, loss:0.6885981673920722\n",
            "Epoch:152, w1 : 0.6072070291888718, w2:0.3560134909743584, Bias:-0.33457011784455276, loss:0.6885946230223732\n",
            "Epoch:153, w1 : 0.6061088339413883, w2:0.355746487846577, Bias:-0.33387967162811283, loss:0.6885910994741469\n",
            "Epoch:154, w1 : 0.6050123799614787, w2:0.35548340140662354, Bias:-0.33319235433852223, loss:0.688587596513574\n",
            "Epoch:155, w1 : 0.6039176920337122, w2:0.3552241369370283, Bias:-0.332508122813531, loss:0.688584113914606\n",
            "Epoch:156, w1 : 0.6028247941106148, w2:0.35496860218695253, Bias:-0.331826934923912, loss:0.6885806514585822\n",
            "Epoch:157, w1 : 0.6017337093349664, w2:0.3547167073074773, Bias:-0.33114874954663137, loss:0.6885772089338696\n",
            "Epoch:158, w1 : 0.6006444600615101, w2:0.35446836478858973, Bias:-0.3304735265387192, loss:0.6885737861355218\n",
            "Epoch:159, w1 : 0.5995570678780926, w2:0.3542234893978225, Bias:-0.3298012267118237, loss:0.6885703828649516\n",
            "Epoch:160, w1 : 0.5984715536262485, w2:0.3539819981205028, Bias:-0.3291318118074296, loss:0.6885669989296249\n",
            "Epoch:161, w1 : 0.5973879374212435, w2:0.3537438101015692, Bias:-0.3284652444727247, loss:0.6885636341427676\n",
            "Epoch:162, w1 : 0.5963062386715909, w2:0.3535088465889149, Bias:-0.3278014882370965, loss:0.6885602883230886\n",
            "Epoch:163, w1 : 0.5952264760980553, w2:0.35327703087821777, Bias:-0.32714050748924384, loss:0.6885569612945162\n",
            "Epoch:164, w1 : 0.5941486677521566, w2:0.35304828825921747, Bias:-0.3264822674548864, loss:0.6885536528859504\n",
            "Epoch:165, w1 : 0.5930728310341872, w2:0.3528225459634028, Bias:-0.32582673417505703, loss:0.6885503629310243\n",
            "Epoch:166, w1 : 0.5919989827107561, w2:0.35259973311307136, Bias:-0.3251738744849615, loss:0.688547091267881\n",
            "Epoch:167, w1 : 0.5909271389318711, w2:0.352379780671726, Bias:-0.3245236559933913, loss:0.6885438377389601\n",
            "Epoch:168, w1 : 0.5898573152475719, w2:0.3521626213957731, Bias:-0.3238760470626742, loss:0.6885406021907957\n",
            "Epoch:169, w1 : 0.5887895266241258, w2:0.3519481897874883, Bias:-0.3232310167891497, loss:0.6885373844738256\n",
            "Epoch:170, w1 : 0.5877237874597973, w2:0.3517364220492166, Bias:-0.32258853498415474, loss:0.6885341844422087\n",
            "Epoch:171, w1 : 0.5866601116002029, w2:0.3515272560387742, Bias:-0.3219485721555065, loss:0.6885310019536518\n",
            "Epoch:172, w1 : 0.5855985123532619, w2:0.35132063122602136, Bias:-0.32131109948947006, loss:0.688527836869249\n",
            "Epoch:173, w1 : 0.5845390025037536, w2:0.3511164886505744, Bias:-0.3206760888331974, loss:0.6885246890533223\n",
            "Epoch:174, w1 : 0.5834815943274917, w2:0.35091477088062795, Bias:-0.3200435126776256, loss:0.688521558373278\n",
            "Epoch:175, w1 : 0.5824262996051255, w2:0.3507154219728581, Bias:-0.31941334414082256, loss:0.6885184446994648\n",
            "Epoch:176, w1 : 0.5813731296355779, w2:0.35051838743337743, Bias:-0.3187855569517687, loss:0.6885153479050417\n",
            "Epoch:177, w1 : 0.5803220952491295, w2:0.3503236141797156, Bias:-0.31816012543456246, loss:0.6885122678658525\n",
            "Epoch:178, w1 : 0.5792732068201584, w2:0.3501310505037972, Bias:-0.31753702449303944, loss:0.6885092044603066\n",
            "Epoch:179, w1 : 0.5782264742795444, w2:0.34994064603589226, Bias:-0.31691622959579363, loss:0.6885061575692646\n",
            "Epoch:180, w1 : 0.577181907126747, w2:0.34975235170951197, Bias:-0.3162977167615909, loss:0.6885031270759318\n",
            "Epoch:181, w1 : 0.5761395144415642, w2:0.3495661197272268, Bias:-0.3156814625451639, loss:0.688500112865756\n",
            "Epoch:182, w1 : 0.5750993048955833, w2:0.3493819035273815, Bias:-0.31506744402337866, loss:0.6884971148263302\n",
            "Epoch:183, w1 : 0.5740612867633282, w2:0.3491996577516842, Bias:-0.3144556387817637, loss:0.6884941328473009\n",
            "Epoch:184, w1 : 0.5730254679331148, w2:0.3490193382136457, Bias:-0.31384602490139074, loss:0.6884911668202811\n",
            "Epoch:185, w1 : 0.5719918559176186, w2:0.3488409018678481, Bias:-0.3132385809460997, loss:0.6884882166387671\n",
            "Epoch:186, w1 : 0.5709604578641654, w2:0.3486643067800197, Bias:-0.31263328595005735, loss:0.6884852821980598\n",
            "Epoch:187, w1 : 0.56993128056475, w2:0.34848951209789575, Bias:-0.31203011940564185, loss:0.688482363395191\n",
            "Epoch:188, w1 : 0.5689043304657906, w2:0.34831647802284416, Bias:-0.31142906125164427, loss:0.6884794601288508\n",
            "Epoch:189, w1 : 0.5678796136776268, w2:0.3481451657822361, Bias:-0.3108300918617792, loss:0.6884765722993217\n",
            "Epoch:190, w1 : 0.5668571359837667, w2:0.3479755376025422, Bias:-0.3102331920334955, loss:0.6884736998084149\n",
            "Epoch:191, w1 : 0.5658369028498903, w2:0.34780755668313473, Bias:-0.3096383429770804, loss:0.6884708425594083\n",
            "Epoch:192, w1 : 0.5648189194326153, w2:0.34764118717077824, Bias:-0.30904552630504883, loss:0.6884680004569893\n",
            "Epoch:193, w1 : 0.5638031905880322, w2:0.34747639413478926, Bias:-0.30845472402180973, loss:0.6884651734072013\n",
            "Epoch:194, w1 : 0.5627897208800133, w2:0.3473131435428487, Bias:-0.30786591851360384, loss:0.6884623613173902\n",
            "Epoch:195, w1 : 0.5617785145883041, w2:0.34715140223744934, Bias:-0.3072790925387043, loss:0.6884595640961557\n",
            "Epoch:196, w1 : 0.5607695757163991, w2:0.3469911379129613, Bias:-0.30669422921787354, loss:0.6884567816533048\n",
            "Epoch:197, w1 : 0.5597629079992118, w2:0.34683231909330037, Bias:-0.3061113120250706, loss:0.6884540138998059\n",
            "Epoch:198, w1 : 0.558758514910541, w2:0.346674915110182, Bias:-0.30553032477840114, loss:0.6884512607477479\n",
            "Epoch:199, w1 : 0.5577563996703403, w2:0.3465188960819471, Bias:-0.30495125163130454, loss:0.6884485221102992\n",
            "Epoch:200, w1 : 0.5567565652517961, w2:0.34636423289294305, Bias:-0.30437407706397146, loss:0.6884457979016696\n",
            "Epoch:201, w1 : 0.5557590143882178, w2:0.3462108971734468, Bias:-0.30379878587498654, loss:0.688443088037074\n",
            "Epoch:202, w1 : 0.5547637495797474, w2:0.3460588612801146, Bias:-0.3032253631731892, loss:0.688440392432698\n",
            "Epoch:203, w1 : 0.5537707730998904, w2:0.3459080982769457, Bias:-0.3026537943697479, loss:0.6884377110056645\n",
            "Epoch:204, w1 : 0.5527800870018755, w2:0.34575858191674547, Bias:-0.3020840651704416, loss:0.6884350436740035\n",
            "Epoch:205, w1 : 0.5517916931248452, w2:0.3456102866230754, Bias:-0.3015161615681436, loss:0.6884323903566213\n",
            "Epoch:206, w1 : 0.5508055930998835, w2:0.3454631874726774, Bias:-0.30095006983550143, loss:0.6884297509732723\n",
            "Epoch:207, w1 : 0.5498217883558842, w2:0.34531726017835923, Bias:-0.30038577651780907, loss:0.6884271254445337\n",
            "Epoch:208, w1 : 0.5488402801252636, w2:0.34517248107232956, Bias:-0.29982326842606516, loss:0.688424513691778\n",
            "Epoch:209, w1 : 0.5478610694495231, w2:0.3450288270899708, Bias:-0.2992625326302131, loss:0.6884219156371494\n",
            "Epoch:210, w1 : 0.5468841571846633, w2:0.34488627575403785, Bias:-0.29870355645255786, loss:0.6884193312035414\n",
            "Epoch:211, w1 : 0.5459095440064567, w2:0.3447448051592719, Bias:-0.2981463274613556, loss:0.6884167603145733\n",
            "Epoch:212, w1 : 0.5449372304155794, w2:0.34460439395741843, Bias:-0.29759083346457027, loss:0.6884142028945711\n",
            "Epoch:213, w1 : 0.5439672167426077, w2:0.3444650213426384, Bias:-0.297037062503794, loss:0.6884116588685449\n",
            "Epoch:214, w1 : 0.5429995031528826, w2:0.3443266670373028, Bias:-0.29648500284832674, loss:0.6884091281621737\n",
            "Epoch:215, w1 : 0.542034089651245, w2:0.34418931127816016, Bias:-0.2959346429894102, loss:0.6884066107017829\n",
            "Epoch:216, w1 : 0.5410709760866463, w2:0.34405293480286736, Bias:-0.29538597163461333, loss:0.6884041064143307\n",
            "Epoch:217, w1 : 0.5401101621566363, w2:0.34391751883687427, Bias:-0.29483897770236417, loss:0.688401615227389\n",
            "Epoch:218, w1 : 0.5391516474117324, w2:0.34378304508065255, Bias:-0.2942936503166251, loss:0.6883991370691298\n",
            "Epoch:219, w1 : 0.5381954312596731, w2:0.34364949569726033, Bias:-0.29374997880170695, loss:0.6883966718683094\n",
            "Epoch:220, w1 : 0.5372415129695592, w2:0.3435168533002329, Bias:-0.29320795267721944, loss:0.6883942195542542\n",
            "Epoch:221, w1 : 0.5362898916758847, w2:0.343385100941792, Bias:-0.2926675616531529, loss:0.6883917800568458\n",
            "Epoch:222, w1 : 0.5353405663824607, w2:0.34325422210136425, Bias:-0.29212879562508914, loss:0.6883893533065104\n",
            "Epoch:223, w1 : 0.5343935359662363, w2:0.3431242006744017, Bias:-0.2915916446695376, loss:0.6883869392342055\n",
            "Epoch:224, w1 : 0.5334487991810168, w2:0.34299502096149526, Bias:-0.2910560990393929, loss:0.6883845377714072\n",
            "Epoch:225, w1 : 0.5325063546610846, w2:0.34286666765777485, Bias:-0.29052214915951197, loss:0.6883821488500999\n",
            "Epoch:226, w1 : 0.531566200924723, w2:0.34273912584258726, Bias:-0.28998978562240624, loss:0.6883797724027655\n",
            "Epoch:227, w1 : 0.5306283363776468, w2:0.3426123809694456, Bias:-0.28945899918404655, loss:0.6883774083623726\n",
            "Epoch:228, w1 : 0.5296927593163426, w2:0.3424864188562423, Bias:-0.2889297807597779, loss:0.6883750566623673\n",
            "Epoch:229, w1 : 0.528759467931319, w2:0.34236122567571964, Bias:-0.28840212142034094, loss:0.688372717236663\n",
            "Epoch:230, w1 : 0.5278284603102716, w2:0.34223678794618995, Bias:-0.2878760123879974, loss:0.6883703900196322\n",
            "Epoch:231, w1 : 0.5268997344411636, w2:0.3421130925225001, Bias:-0.2873514450327567, loss:0.6883680749460973\n",
            "Epoch:232, w1 : 0.5259732882152239, w2:0.34199012658723293, Bias:-0.2868284108687014, loss:0.6883657719513229\n",
            "Epoch:233, w1 : 0.5250491194298671, w2:0.34186787764214, Bias:-0.2863069015504084, loss:0.6883634809710075\n",
            "Epoch:234, w1 : 0.5241272257915338, w2:0.3417463334997991, Bias:-0.28578690886946384, loss:0.6883612019412763\n",
            "Epoch:235, w1 : 0.5232076049184573, w2:0.3416254822754911, Bias:-0.28526842475106906, loss:0.6883589347986733\n",
            "Epoch:236, w1 : 0.5222902543433551, w2:0.34150531237929005, Bias:-0.2847514412507351, loss:0.6883566794801558\n",
            "Epoch:237, w1 : 0.5213751715160498, w2:0.34138581250836086, Bias:-0.28423595055106354, loss:0.6883544359230857\n",
            "Epoch:238, w1 : 0.5204623538060201, w2:0.3412669716394597, Bias:-0.28372194495861164, loss:0.688352204065225\n",
            "Epoch:239, w1 : 0.5195517985048831, w2:0.34114877902163065, Bias:-0.28320941690083895, loss:0.6883499838447287\n",
            "Epoch:240, w1 : 0.5186435028288116, w2:0.34103122416909515, Bias:-0.282698358923134, loss:0.6883477752001389\n",
            "Epoch:241, w1 : 0.5177374639208858, w2:0.34091429685432717, Bias:-0.2821887636859185, loss:0.6883455780703799\n",
            "Epoch:242, w1 : 0.5168336788533838, w2:0.34079798710131093, Bias:-0.28168062396182697, loss:0.6883433923947516\n",
            "Epoch:243, w1 : 0.5159321446300095, w2:0.3406822851789754, Bias:-0.28117393263296026, loss:0.6883412181129261\n",
            "Epoch:244, w1 : 0.5150328581880615, w2:0.3405671815948014, Bias:-0.28066868268821055, loss:0.6883390551649403\n",
            "Epoch:245, w1 : 0.5141358164005452, w2:0.3404526670885964, Bias:-0.28016486722065626, loss:0.6883369034911929\n",
            "Epoch:246, w1 : 0.5132410160782267, w2:0.3403387326264329, Bias:-0.27966247942502476, loss:0.6883347630324395\n",
            "Epoch:247, w1 : 0.5123484539716334, w2:0.34022536939474607, Bias:-0.2791615125952215, loss:0.688332633729787\n",
            "Epoch:248, w1 : 0.5114581267730004, w2:0.34011256879458635, Bias:-0.27866196012192335, loss:0.6883305155246909\n",
            "Epoch:249, w1 : 0.5105700311181647, w2:0.3400003224360228, Bias:-0.27816381549023483, loss:0.6883284083589497\n",
            "Epoch:250, w1 : 0.5096841635884093, w2:0.3398886221326937, Bias:-0.27766707227740556, loss:0.688326312174702\n",
            "Epoch:251, w1 : 0.5088005207122578, w2:0.3397774598965004, Bias:-0.2771717241506068, loss:0.6883242269144217\n",
            "Epoch:252, w1 : 0.5079190989672207, w2:0.33966682793243963, Bias:-0.27667776486476653, loss:0.6883221525209152\n",
            "Epoch:253, w1 : 0.5070398947814949, w2:0.33955671863357284, Bias:-0.2761851882604603, loss:0.6883200889373166\n",
            "Epoch:254, w1 : 0.5061629045356185, w2:0.3394471245761265, Bias:-0.27569398826185765, loss:0.6883180361070856\n",
            "Epoch:255, w1 : 0.50528812456408, w2:0.3393380385147218, Bias:-0.27520415887472155, loss:0.6883159939740028\n",
            "Epoch:256, w1 : 0.5044155511568853, w2:0.3392294533777289, Bias:-0.27471569418446024, loss:0.6883139624821671\n",
            "Epoch:257, w1 : 0.5035451805610821, w2:0.33912136226274436, Bias:-0.27422858835422953, loss:0.6883119415759927\n",
            "Epoch:258, w1 : 0.5026770089822439, w2:0.3390137584321858, Bias:-0.2737428356230849, loss:0.6883099312002058\n",
            "Epoch:259, w1 : 0.5018110325859135, w2:0.33890663530900345, Bias:-0.2732584303041811, loss:0.688307931299841\n",
            "Epoch:260, w1 : 0.5009472474990083, w2:0.33879998647250376, Bias:-0.2727753667830194, loss:0.688305941820239\n",
            "Epoch:261, w1 : 0.5000856498111876, w2:0.3386938056542828, Bias:-0.2722936395157395, loss:0.6883039627070445\n",
            "Epoch:262, w1 : 0.49922623557618284, w2:0.3385880867342665, Bias:-0.2718132430274567, loss:0.6883019939062022\n",
            "Epoch:263, w1 : 0.4983690008130924, w2:0.3384828237368545, Bias:-0.2713341719106418, loss:0.6883000353639546\n",
            "Epoch:264, w1 : 0.4975139415076414, w2:0.33837801082716584, Bias:-0.27085642082354344, loss:0.6882980870268393\n",
            "Epoch:265, w1 : 0.4966610536134076, w2:0.33827364230738277, Bias:-0.27037998448865114, loss:0.6882961488416871\n",
            "Epoch:266, w1 : 0.4958103330530141, w2:0.33816971261319073, Bias:-0.26990485769119843, loss:0.6882942207556189\n",
            "Epoch:267, w1 : 0.4949617757192898, w2:0.3380662163103117, Bias:-0.2694310352777049, loss:0.6882923027160434\n",
            "Epoch:268, w1 : 0.49411537747639894, w2:0.33796314809112865, Bias:-0.268958512154556, loss:0.688290394670655\n",
            "Epoch:269, w1 : 0.4932711341609397, w2:0.3378605027713987, Bias:-0.26848728328661997, loss:0.6882884965674314\n",
            "Epoch:270, w1 : 0.49242904158301304, w2:0.3377582752870522, Bias:-0.26801734369590025, loss:0.6882866083546311\n",
            "Epoch:271, w1 : 0.49158909552726304, w2:0.33765646069107647, Bias:-0.2675486884602232, loss:0.688284729980792\n",
            "Epoch:272, w1 : 0.4907512917538887, w2:0.3375550541504805, Bias:-0.2670813127119598, loss:0.6882828613947287\n",
            "Epoch:273, w1 : 0.4899156259996285, w2:0.3374540509433402, Bias:-0.2666152116367802, loss:0.6882810025455302\n",
            "Epoch:274, w1 : 0.48908209397871816, w2:0.3373534464559206, Bias:-0.26615038047244116, loss:0.6882791533825586\n",
            "Epoch:275, w1 : 0.4882506913838223, w2:0.33725323617987385, Bias:-0.26568681450760423, loss:0.6882773138554465\n",
            "Epoch:276, w1 : 0.48742141388694127, w2:0.3371534157095108, Bias:-0.265224509080685, loss:0.6882754839140954\n",
            "Epoch:277, w1 : 0.48659425714029264, w2:0.33705398073914394, Bias:-0.26476345957873204, loss:0.6882736635086738\n",
            "Epoch:278, w1 : 0.48576921677716917, w2:0.3369549270605005, Bias:-0.2643036614363348, loss:0.688271852589615\n",
            "Epoch:279, w1 : 0.4849462884127733, w2:0.33685625056020296, Bias:-0.26384511013455997, loss:0.6882700511076159\n",
            "Epoch:280, w1 : 0.484125467645029, w2:0.3367579472173161, Bias:-0.26338780119991484, loss:0.6882682590136342\n",
            "Epoch:281, w1 : 0.483306750055371, w2:0.3366600131009582, Bias:-0.26293173020333815, loss:0.6882664762588878\n",
            "Epoch:282, w1 : 0.48249013120951306, w2:0.3365624443679749, Bias:-0.2624768927592166, loss:0.6882647027948524\n",
            "Epoch:283, w1 : 0.4816756066581951, w2:0.33646523726067434, Bias:-0.2620232845244268, loss:0.68826293857326\n",
            "Epoch:284, w1 : 0.4808631719379095, w2:0.3363683881046215, Bias:-0.26157090119740223, loss:0.688261183546097\n",
            "Epoch:285, w1 : 0.4800528225716079, w2:0.3362718933064905, Bias:-0.2611197385172238, loss:0.6882594376656027\n",
            "Epoch:286, w1 : 0.4792445540693886, w2:0.3361757493519732, Bias:-0.2606697922627345, loss:0.688257700884268\n",
            "Epoch:287, w1 : 0.4784383619291647, w2:0.336079952803743, Bias:-0.2602210582516763, loss:0.6882559731548332\n",
            "Epoch:288, w1 : 0.4776342416373145, w2:0.33598450029947136, Bias:-0.2597735323398497, loss:0.6882542544302871\n",
            "Epoch:289, w1 : 0.47683218866931343, w2:0.3358893885498972, Bias:-0.2593272104202947, loss:0.6882525446638648\n",
            "Epoch:290, w1 : 0.4760321984903489, w2:0.3357946143369463, Bias:-0.2588820884224932, loss:0.6882508438090466\n",
            "Epoch:291, w1 : 0.4752342665559181, w2:0.3357001745119003, Bias:-0.25843816231159145, loss:0.688249151819557\n",
            "Epoch:292, w1 : 0.47443838831240936, w2:0.335606065993614, Bias:-0.25799542808764275, loss:0.6882474686493615\n",
            "Epoch:293, w1 : 0.4736445591976673, w2:0.3355122857667786, Bias:-0.25755388178486993, loss:0.6882457942526669\n",
            "Epoch:294, w1 : 0.47285277464154246, w2:0.3354188308802316, Bias:-0.25711351947094624, loss:0.6882441285839196\n",
            "Epoch:295, w1 : 0.4720630300664256, w2:0.33532569844531007, Bias:-0.25667433724629507, loss:0.688242471597803\n",
            "Epoch:296, w1 : 0.47127532088776725, w2:0.33523288563424763, Bias:-0.25623633124340756, loss:0.6882408232492377\n",
            "Epoch:297, w1 : 0.47048964251458286, w2:0.3351403896786133, Bias:-0.2557994976261777, loss:0.6882391834933789\n",
            "Epoch:298, w1 : 0.46970599034994376, w2:0.33504820786779155, Bias:-0.2553638325892545, loss:0.6882375522856153\n",
            "Epoch:299, w1 : 0.4689243597914545, w2:0.3349563375475016, Bias:-0.25492933235741067, loss:0.6882359295815687\n",
            "Epoch:300, w1 : 0.4681447462317169, w2:0.33486477611835624, Bias:-0.2544959931849279, loss:0.6882343153370908\n",
            "Epoch:301, w1 : 0.467367145058781, w2:0.33477352103445807, Bias:-0.2540638113549971, loss:0.688232709508264\n",
            "Epoch:302, w1 : 0.4665915516565836, w2:0.3346825698020325, Bias:-0.2536327831791349, loss:0.6882311120513984\n",
            "Epoch:303, w1 : 0.4658179614053743, w2:0.3345919199780968, Bias:-0.2532029049966142, loss:0.6882295229230315\n",
            "Epoch:304, w1 : 0.4650463696821296, w2:0.33450156916916396, Bias:-0.2527741731739098, loss:0.6882279420799262\n",
            "Epoch:305, w1 : 0.46427677186095545, w2:0.33441151502998034, Bias:-0.25234658410415833, loss:0.6882263694790706\n",
            "Epoch:306, w1 : 0.46350916331347847, w2:0.33432175526229674, Bias:-0.25192013420663123, loss:0.6882248050776753\n",
            "Epoch:307, w1 : 0.4627435394092259, w2:0.3342322876136714, Bias:-0.25149481992622197, loss:0.6882232488331731\n",
            "Epoch:308, w1 : 0.46197989551599494, w2:0.33414310987630463, Bias:-0.25107063773294586, loss:0.6882217007032183\n",
            "Epoch:309, w1 : 0.4612182270002117, w2:0.33405421988590356, Bias:-0.25064758412145277, loss:0.6882201606456839\n",
            "Epoch:310, w1 : 0.46045852922727987, w2:0.3339656155205772, Bias:-0.2502256556105521, loss:0.6882186286186619\n",
            "Epoch:311, w1 : 0.45970079756191945, w2:0.33387729469975996, Bias:-0.24980484874275008, loss:0.6882171045804609\n",
            "Epoch:312, w1 : 0.45894502736849574, w2:0.3337892553831636, Bias:-0.24938516008379852, loss:0.6882155884896063\n",
            "Epoch:313, w1 : 0.45819121401133917, w2:0.33370149556975676, Bias:-0.2489665862222553, loss:0.6882140803048371\n",
            "Epoch:314, w1 : 0.45743935285505577, w2:0.33361401329677076, Bias:-0.24854912376905575, loss:0.6882125799851074\n",
            "Epoch:315, w1 : 0.4566894392648288, w2:0.33352680663873213, Bias:-0.248132769357095, loss:0.6882110874895828\n",
            "Epoch:316, w1 : 0.4559414686067116, w2:0.33343987370651973, Bias:-0.24771751964082103, loss:0.6882096027776404\n",
            "Epoch:317, w1 : 0.45519543624791214, w2:0.33335321264644713, Bias:-0.24730337129583777, loss:0.6882081258088679\n",
            "Epoch:318, w1 : 0.45445133755706935, w2:0.33326682163936877, Bias:-0.24689032101851832, loss:0.6882066565430619\n",
            "Epoch:319, w1 : 0.45370916790452115, w2:0.33318069889980967, Bias:-0.24647836552562802, loss:0.6882051949402266\n",
            "Epoch:320, w1 : 0.45296892266256517, w2:0.3330948426751176, Bias:-0.2460675015539569, loss:0.6882037409605736\n",
            "Epoch:321, w1 : 0.45223059720571146, w2:0.3330092512446378, Bias:-0.2456577258599615, loss:0.6882022945645199\n",
            "Epoch:322, w1 : 0.451494186910928, w2:0.33292392291890927, Bias:-0.24524903521941563, loss:0.6882008557126877\n",
            "Epoch:323, w1 : 0.45075968715787906, w2:0.33283885603888175, Bias:-0.24484142642706982, loss:0.6881994243659023\n",
            "Epoch:324, w1 : 0.4500270933291563, w2:0.3327540489751536, Bias:-0.2444348962963196, loss:0.6881980004851914\n",
            "Epoch:325, w1 : 0.44929640081050354, w2:0.3326695001272294, Bias:-0.2440294416588818, loss:0.6881965840317843\n",
            "Epoch:326, w1 : 0.4485676049910343, w2:0.33258520792279705, Bias:-0.24362505936447906, loss:0.6881951749671107\n",
            "Epoch:327, w1 : 0.4478407012634434, w2:0.33250117081702374, Bias:-0.2432217462805324, loss:0.6881937732527998\n",
            "Epoch:328, w1 : 0.4471156850242119, w2:0.33241738729187037, Bias:-0.24281949929186117, loss:0.6881923788506791\n",
            "Epoch:329, w1 : 0.44639255167380626, w2:0.3323338558554239, Bias:-0.24241831530039076, loss:0.6881909917227725\n",
            "Epoch:330, w1 : 0.4456712966168711, w2:0.332250575041247, Bias:-0.24201819122486745, loss:0.688189611831301\n",
            "Epoch:331, w1 : 0.44495191526241673, w2:0.33216754340774507, Bias:-0.24161912400058036, loss:0.6881882391386809\n",
            "Epoch:332, w1 : 0.4442344030240004, w2:0.3320847595375494, Bias:-0.2412211105790904, loss:0.6881868736075215\n",
            "Epoch:333, w1 : 0.44351875531990265, w2:0.3320022220369167, Bias:-0.24082414792796594, loss:0.6881855152006262\n",
            "Epoch:334, w1 : 0.44280496757329785, w2:0.3319199295351443, Bias:-0.2404282330305249, loss:0.6881841638809906\n",
            "Epoch:335, w1 : 0.4420930352124199, w2:0.33183788068400055, Bias:-0.24003336288558338, loss:0.6881828196118007\n",
            "Epoch:336, w1 : 0.4413829536707225, w2:0.33175607415717007, Bias:-0.23963953450721046, loss:0.6881814823564331\n",
            "Epoch:337, w1 : 0.4406747183870348, w2:0.3316745086497137, Bias:-0.239246744924489, loss:0.6881801520784533\n",
            "Epoch:338, w1 : 0.4399683248057121, w2:0.3315931828775424, Bias:-0.23885499118128245, loss:0.6881788287416154\n",
            "Epoch:339, w1 : 0.4392637683767817, w2:0.33151209557690486, Bias:-0.23846427033600734, loss:0.6881775123098601\n",
            "Epoch:340, w1 : 0.43856104455608486, w2:0.3314312455038884, Bias:-0.23807457946141125, loss:0.688176202747315\n",
            "Epoch:341, w1 : 0.4378601488054133, w2:0.33135063143393345, Bias:-0.23768591564435643, loss:0.6881749000182917\n",
            "Epoch:342, w1 : 0.43716107659264236, w2:0.3312702521613598, Bias:-0.23729827598560865, loss:0.6881736040872878\n",
            "Epoch:343, w1 : 0.43646382339185946, w2:0.331190106498906, Bias:-0.23691165759963106, loss:0.6881723149189828\n",
            "Epoch:344, w1 : 0.4357683846834885, w2:0.3311101932772805, Bias:-0.23652605761438342, loss:0.6881710324782393\n",
            "Epoch:345, w1 : 0.43507475595441036, w2:0.3310305113447242, Bias:-0.2361414731711258, loss:0.688169756730101\n",
            "Epoch:346, w1 : 0.43438293269807965, w2:0.3309510595665852, Bias:-0.23575790142422742, loss:0.6881684876397924\n",
            "Epoch:347, w1 : 0.4336929104146374, w2:0.33087183682490356, Bias:-0.23537533954098, loss:0.6881672251727174\n",
            "Epoch:348, w1 : 0.4330046846110205, w2:0.3307928420180078, Bias:-0.23499378470141546, loss:0.6881659692944584\n",
            "Epoch:349, w1 : 0.43231825080106706, w2:0.33071407406012143, Bias:-0.23461323409812843, loss:0.6881647199707758\n",
            "Epoch:350, w1 : 0.43163360450561883, w2:0.3306355318809801, Bias:-0.23423368493610255, loss:0.6881634771676065\n",
            "Epoch:351, w1 : 0.43095074125261973, w2:0.3305572144254582, Bias:-0.23385513443254147, loss:0.6881622408510635\n",
            "Epoch:352, w1 : 0.4302696565772116, w2:0.3304791206532057, Bias:-0.23347757981670345, loss:0.6881610109874351\n",
            "Epoch:353, w1 : 0.42959034602182633, w2:0.3304012495382942, Bias:-0.23310101832974026, loss:0.688159787543183\n",
            "Epoch:354, w1 : 0.428912805136275, w2:0.3303236000688721, Bias:-0.23272544722453978, loss:0.6881585704849426\n",
            "Epoch:355, w1 : 0.42823702947783415, w2:0.33024617124682915, Bias:-0.2323508637655724, loss:0.688157359779521\n",
            "Epoch:356, w1 : 0.427563014611329, w2:0.3301689620874691, Bias:-0.23197726522874104, loss:0.688156155393898\n",
            "Epoch:357, w1 : 0.4268907561092136, w2:0.3300919716191916, Bias:-0.2316046489012349, loss:0.688154957295222\n",
            "Epoch:358, w1 : 0.4262202495516485, w2:0.3300151988831818, Bias:-0.23123301208138633, loss:0.6881537654508129\n",
            "Epoch:359, w1 : 0.42555149052657554, w2:0.3299386429331082, Bias:-0.2308623520785316, loss:0.6881525798281583\n",
            "Epoch:360, w1 : 0.42488447462978995, w2:0.3298623028348285, Bias:-0.2304926662128744, loss:0.6881514003949143\n",
            "Epoch:361, w1 : 0.4242191974650101, w2:0.3297861776661028, Bias:-0.23012395181535306, loss:0.6881502271189034\n",
            "Epoch:362, w1 : 0.4235556546439443, w2:0.3297102665163147, Bias:-0.2297562062275105, loss:0.6881490599681148\n",
            "Epoch:363, w1 : 0.42289384178635575, w2:0.3296345684861991, Bias:-0.22938942680136745, loss:0.688147898910703\n",
            "Epoch:364, w1 : 0.4222337545201247, w2:0.3295590826875775, Bias:-0.22902361089929854, loss:0.6881467439149871\n",
            "Epoch:365, w1 : 0.42157538848130827, w2:0.32948380824309986, Bias:-0.22865875589391135, loss:0.6881455949494495\n",
            "Epoch:366, w1 : 0.4209187393141984, w2:0.3294087442859935, Bias:-0.22829485916792824, loss:0.6881444519827354\n",
            "Epoch:367, w1 : 0.42026380267137714, w2:0.32933388995981816, Bias:-0.22793191811407085, loss:0.6881433149836524\n",
            "Epoch:368, w1 : 0.41961057421377035, w2:0.32925924441822774, Bias:-0.2275699301349473, loss:0.6881421839211689\n",
            "Epoch:369, w1 : 0.41895904961069874, w2:0.32918480682473783, Bias:-0.2272088926429422, loss:0.6881410587644137\n",
            "Epoch:370, w1 : 0.41830922453992736, w2:0.32911057635249974, Bias:-0.22684880306010874, loss:0.6881399394826753\n",
            "Epoch:371, w1 : 0.4176610946877129, w2:0.32903655218407996, Bias:-0.2264896588180637, loss:0.6881388260454003\n",
            "Epoch:372, w1 : 0.41701465574884916, w2:0.3289627335112455, Bias:-0.2261314573578847, loss:0.688137718422194\n",
            "Epoch:373, w1 : 0.4163699034267106, w2:0.3288891195347549, Bias:-0.2257741961300096, loss:0.6881366165828181\n",
            "Epoch:374, w1 : 0.4157268334332942, w2:0.3288157094641545, Bias:-0.22541787259413842, loss:0.6881355204971911\n",
            "Epoch:375, w1 : 0.41508544148925947, w2:0.32874250251757997, Bias:-0.2250624842191375, loss:0.6881344301353863\n",
            "Epoch:376, w1 : 0.4144457233239668, w2:0.3286694979215631, Bias:-0.22470802848294552, loss:0.688133345467632\n",
            "Epoch:377, w1 : 0.413807674675514, w2:0.32859669491084337, Bias:-0.22435450287248204, loss:0.6881322664643105\n",
            "Epoch:378, w1 : 0.41317129129077157, w2:0.32852409272818467, Bias:-0.2240019048835577, loss:0.688131193095957\n",
            "Epoch:379, w1 : 0.412536568925416, w2:0.3284516906241966, Bias:-0.22365023202078674, loss:0.6881301253332586\n",
            "Epoch:380, w1 : 0.4119035033439618, w2:0.3283794878571603, Bias:-0.2232994817975012, loss:0.6881290631470552\n",
            "Epoch:381, w1 : 0.4112720903197919, w2:0.328307483692859, Bias:-0.2229496517356672, loss:0.688128006508336\n",
            "Epoch:382, w1 : 0.4106423256351867, w2:0.32823567740441256, Bias:-0.22260073936580305, loss:0.6881269553882403\n",
            "Epoch:383, w1 : 0.4100142050813517, w2:0.3281640682721168, Bias:-0.222252742226899, loss:0.6881259097580579\n",
            "Epoch:384, w1 : 0.4093877244584437, w2:0.32809265558328654, Bias:-0.22190565786633895, loss:0.6881248695892256\n",
            "Epoch:385, w1 : 0.4087628795755956, w2:0.32802143863210287, Bias:-0.2215594838398237, loss:0.6881238348533288\n",
            "Epoch:386, w1 : 0.4081396662509402, w2:0.32795041671946434, Bias:-0.22121421771129604, loss:0.688122805522099\n",
            "Epoch:387, w1 : 0.40751808031163256, w2:0.32787958915284193, Bias:-0.2208698570528672, loss:0.6881217815674144\n",
            "Epoch:388, w1 : 0.40689811759387073, w2:0.32780895524613773, Bias:-0.22052639944474522, loss:0.6881207629612988\n",
            "Epoch:389, w1 : 0.4062797739429162, w2:0.3277385143195473, Bias:-0.2201838424751645, loss:0.6881197496759199\n",
            "Epoch:390, w1 : 0.4056630452131123, w2:0.32766826569942575, Bias:-0.2198421837403171, loss:0.6881187416835902\n",
            "Epoch:391, w1 : 0.405047927267902, w2:0.32759820871815676, Bias:-0.21950142084428545, loss:0.6881177389567646\n",
            "Epoch:392, w1 : 0.4044344159798444, w2:0.32752834271402553, Bias:-0.21916155139897633, loss:0.6881167414680414\n",
            "Epoch:393, w1 : 0.4038225072306303, w2:0.3274586670310946, Bias:-0.21882257302405647, loss:0.6881157491901595\n",
            "Epoch:394, w1 : 0.4032121969110964, w2:0.327389181019083, Bias:-0.21848448334688933, loss:0.6881147620959993\n",
            "Epoch:395, w1 : 0.40260348092123904, w2:0.32731988403324846, Bias:-0.21814728000247327, loss:0.6881137801585819\n",
            "Epoch:396, w1 : 0.4019963551702266, w2:0.3272507754342727, Bias:-0.21781096063338096, loss:0.6881128033510677\n",
            "Epoch:397, w1 : 0.40139081557641065, w2:0.32718185458814963, Bias:-0.2174755228897, loss:0.6881118316467553\n",
            "Epoch:398, w1 : 0.400786858067337, w2:0.32711312086607625, Bias:-0.217140964428975, loss:0.6881108650190827\n",
            "Epoch:399, w1 : 0.40018447857975503, w2:0.3270445736443465, Bias:-0.21680728291615037, loss:0.6881099034416237\n",
            "Epoch:400, w1 : 0.3995836730596268, w2:0.326976212304248, Bias:-0.2164744760235148, loss:0.6881089468880903\n",
            "Epoch:401, w1 : 0.3989844374621346, w2:0.32690803623196085, Bias:-0.21614254143064646, loss:0.6881079953323299\n",
            "Epoch:402, w1 : 0.39838676775168835, w2:0.32684004481845974, Bias:-0.21581147682435955, loss:0.6881070487483248\n",
            "Epoch:403, w1 : 0.39779065990193196, w2:0.32677223745941786, Bias:-0.21548127989865176, loss:0.6881061071101929\n",
            "Epoch:404, w1 : 0.39719610989574866, w2:0.3267046135551139, Bias:-0.2151519483546528, loss:0.6881051703921853\n",
            "Epoch:405, w1 : 0.3966031137252659, w2:0.32663717251034075, Bias:-0.21482347990057402, loss:0.6881042385686866\n",
            "Epoch:406, w1 : 0.39601166739185933, w2:0.32656991373431715, Bias:-0.214495872251659, loss:0.6881033116142138\n",
            "Epoch:407, w1 : 0.3954217669061561, w2:0.32650283664060115, Bias:-0.21416912313013503, loss:0.6881023895034162\n",
            "Epoch:408, w1 : 0.3948334082880376, w2:0.326435940647006, Bias:-0.2138432302651655, loss:0.6881014722110738\n",
            "Epoch:409, w1 : 0.3942465875666412, w2:0.3263692251755179, Bias:-0.21351819139280337, loss:0.6881005597120973\n",
            "Epoch:410, w1 : 0.3936613007803619, w2:0.3263026896522164, Bias:-0.21319400425594542, loss:0.6880996519815276\n",
            "Epoch:411, w1 : 0.39307754397685246, w2:0.32623633350719594, Bias:-0.21287066660428736, loss:0.6880987489945343\n",
            "Epoch:412, w1 : 0.39249531321302383, w2:0.32617015617449024, Bias:-0.2125481761942798, loss:0.6880978507264162\n",
            "Epoch:413, w1 : 0.39191460455504445, w2:0.326104157091998, Bias:-0.21222653078908504, loss:0.6880969571525988\n",
            "Epoch:414, w1 : 0.391335414078339, w2:0.32603833570141094, Bias:-0.21190572815853478, loss:0.6880960682486361\n",
            "Epoch:415, w1 : 0.3907577378675867, w2:0.3259726914481431, Bias:-0.21158576607908836, loss:0.6880951839902084\n",
            "Epoch:416, w1 : 0.3901815720167192, w2:0.3259072237812626, Bias:-0.21126664233379197, loss:0.6880943043531215\n",
            "Epoch:417, w1 : 0.3896069126289175, w2:0.3258419321534243, Bias:-0.21094835471223858, loss:0.6880934293133066\n",
            "Epoch:418, w1 : 0.38903375581660865, w2:0.325776816020805, Bias:-0.21063090101052856, loss:0.6880925588468196\n",
            "Epoch:419, w1 : 0.38846209770146206, w2:0.3257118748430397, Bias:-0.21031427903123098, loss:0.6880916929298406\n",
            "Epoch:420, w1 : 0.3878919344143849, w2:0.32564710808315966, Bias:-0.20999848658334558, loss:0.6880908315386726\n",
            "Epoch:421, w1 : 0.38732326209551754, w2:0.32558251520753195, Bias:-0.20968352148226557, loss:0.6880899746497419\n",
            "Epoch:422, w1 : 0.38675607689422803, w2:0.3255180956858005, Bias:-0.20936938154974088, loss:0.6880891222395962\n",
            "Epoch:423, w1 : 0.3861903749691065, w2:0.3254538489908287, Bias:-0.20905606461384219, loss:0.6880882742849057\n",
            "Epoch:424, w1 : 0.38562615248795895, w2:0.3253897745986435, Bias:-0.2087435685089255, loss:0.6880874307624606\n",
            "Epoch:425, w1 : 0.3850634056278005, w2:0.3253258719883806, Bias:-0.20843189107559737, loss:0.688086591649171\n",
            "Epoch:426, w1 : 0.38450213057484867, w2:0.32526214064223136, Bias:-0.20812103016068073, loss:0.6880857569220683\n",
            "Epoch:427, w1 : 0.3839423235245157, w2:0.3251985800453908, Bias:-0.20781098361718117, loss:0.6880849265583009\n",
            "Epoch:428, w1 : 0.3833839806814009, w2:0.32513518968600696, Bias:-0.20750174930425402, loss:0.6880841005351364\n",
            "Epoch:429, w1 : 0.38282709825928235, w2:0.3250719690551316, Bias:-0.20719332508717173, loss:0.6880832788299605\n",
            "Epoch:430, w1 : 0.38227167248110844, w2:0.3250089176466718, Bias:-0.20688570883729193, loss:0.688082461420276\n",
            "Epoch:431, w1 : 0.38171769957898893, w2:0.32494603495734337, Bias:-0.20657889843202593, loss:0.6880816482837019\n",
            "Epoch:432, w1 : 0.3811651757941858, w2:0.32488332048662477, Bias:-0.20627289175480784, loss:0.6880808393979735\n",
            "Epoch:433, w1 : 0.3806140973771035, w2:0.3248207737367124, Bias:-0.2059676866950641, loss:0.6880800347409409\n",
            "Epoch:434, w1 : 0.3800644605872792, w2:0.32475839421247726, Bias:-0.20566328114818344, loss:0.68807923429057\n",
            "Epoch:435, w1 : 0.37951626169337255, w2:0.3246961814214222, Bias:-0.20535967301548746, loss:0.6880784380249401\n",
            "Epoch:436, w1 : 0.3789694969731551, w2:0.32463413487364057, Bias:-0.20505686020420158, loss:0.6880776459222443\n",
            "Epoch:437, w1 : 0.37842416271349943, w2:0.32457225408177576, Bias:-0.20475484062742638, loss:0.688076857960789\n",
            "Epoch:438, w1 : 0.37788025521036833, w2:0.3245105385609817, Bias:-0.20445361220410954, loss:0.6880760741189924\n",
            "Epoch:439, w1 : 0.3773377707688031, w2:0.3244489878288845, Bias:-0.20415317285901802, loss:0.6880752943753851\n",
            "Epoch:440, w1 : 0.37679670570291207, w2:0.3243876014055446, Bias:-0.2038535205227108, loss:0.6880745187086091\n",
            "Epoch:441, w1 : 0.3762570563358588, w2:0.3243263788134205, Bias:-0.20355465313151194, loss:0.6880737470974169\n",
            "Epoch:442, w1 : 0.37571881899984966, w2:0.3242653195773327, Bias:-0.20325656862748412, loss:0.6880729795206708\n",
            "Epoch:443, w1 : 0.3751819900361216, w2:0.3242044232244289, Bias:-0.20295926495840244, loss:0.6880722159573435\n",
            "Epoch:444, w1 : 0.3746465657949296, w2:0.32414368928415005, Bias:-0.20266274007772872, loss:0.688071456386516\n",
            "Epoch:445, w1 : 0.3741125426355336, w2:0.324083117288197, Bias:-0.20236699194458613, loss:0.6880707007873781\n",
            "Epoch:446, w1 : 0.37357991692618553, w2:0.3240227067704982, Bias:-0.20207201852373408, loss:0.6880699491392276\n",
            "Epoch:447, w1 : 0.37304868504411604, w2:0.32396245726717804, Bias:-0.20177781778554363, loss:0.6880692014214691\n",
            "Epoch:448, w1 : 0.3725188433755209, w2:0.32390236831652575, Bias:-0.2014843877059731, loss:0.6880684576136146\n",
            "Epoch:449, w1 : 0.37199038831554737, w2:0.32384243945896557, Bias:-0.20119172626654414, loss:0.6880677176952821\n",
            "Epoch:450, w1 : 0.3714633162682804, w2:0.32378267023702717, Bias:-0.20089983145431795, loss:0.6880669816461957\n",
            "Epoch:451, w1 : 0.3709376236467283, w2:0.32372306019531694, Bias:-0.20060870126187197, loss:0.6880662494461838\n",
            "Epoch:452, w1 : 0.37041330687280855, w2:0.32366360888048995, Bias:-0.20031833368727686, loss:0.6880655210751802\n",
            "Epoch:453, w1 : 0.3698903623773336, w2:0.3236043158412227, Bias:-0.20002872673407374, loss:0.6880647965132225\n",
            "Epoch:454, w1 : 0.36936878659999584, w2:0.3235451806281861, Bias:-0.19973987841125163, loss:0.6880640757404518\n",
            "Epoch:455, w1 : 0.3688485759893533, w2:0.3234862027940198, Bias:-0.19945178673322544, loss:0.6880633587371124\n",
            "Epoch:456, w1 : 0.3683297270028142, w2:0.3234273818933063, Bias:-0.19916444971981398, loss:0.6880626454835508\n",
            "Epoch:457, w1 : 0.36781223610662234, w2:0.32336871748254636, Bias:-0.19887786539621835, loss:0.6880619359602159\n",
            "Epoch:458, w1 : 0.36729609977584154, w2:0.3233102091201347, Bias:-0.19859203179300067, loss:0.6880612301476574\n",
            "Epoch:459, w1 : 0.3667813144943405, w2:0.323251856366336, Bias:-0.1983069469460629, loss:0.6880605280265263\n",
            "Epoch:460, w1 : 0.36626787675477696, w2:0.32319365878326206, Bias:-0.1980226088966261, loss:0.6880598295775743\n",
            "Epoch:461, w1 : 0.3657557830585824, w2:0.32313561593484896, Bias:-0.19773901569120975, loss:0.6880591347816523\n",
            "Epoch:462, w1 : 0.36524502991594615, w2:0.3230777273868351, Bias:-0.19745616538161148, loss:0.6880584436197108\n",
            "Epoch:463, w1 : 0.3647356138457994, w2:0.3230199927067395, Bias:-0.19717405602488694, loss:0.6880577560727998\n",
            "Epoch:464, w1 : 0.3642275313757992, w2:0.3229624114638406, Bias:-0.19689268568333, loss:0.6880570721220668\n",
            "Epoch:465, w1 : 0.36372077904231254, w2:0.32290498322915595, Bias:-0.19661205242445295, loss:0.6880563917487571\n",
            "Epoch:466, w1 : 0.3632153533903998, w2:0.3228477075754219, Bias:-0.1963321543209673, loss:0.688055714934214\n",
            "Epoch:467, w1 : 0.36271125097379864, w2:0.32279058407707395, Bias:-0.19605298945076435, loss:0.6880550416598774\n",
            "Epoch:468, w1 : 0.3622084683549075, w2:0.32273361231022735, Bias:-0.19577455589689638, loss:0.688054371907283\n",
            "Epoch:469, w1 : 0.3617070021047689, w2:0.32267679185265863, Bias:-0.1954968517475577, loss:0.6880537056580632\n",
            "Epoch:470, w1 : 0.36120684880305304, w2:0.32262012228378695, Bias:-0.19521987509606623, loss:0.6880530428939452\n",
            "Epoch:471, w1 : 0.3607080050380409, w2:0.3225636031846564, Bias:-0.19494362404084492, loss:0.688052383596751\n",
            "Epoch:472, w1 : 0.36021046740660756, w2:0.32250723413791815, Bias:-0.19466809668540372, loss:0.6880517277483972\n",
            "Epoch:473, w1 : 0.3597142325142051, w2:0.3224510147278136, Bias:-0.19439329113832152, loss:0.688051075330894\n",
            "Epoch:474, w1 : 0.3592192969748458, w2:0.3223949445401575, Bias:-0.19411920551322823, loss:0.6880504263263456\n",
            "Epoch:475, w1 : 0.358725657411085, w2:0.32233902316232144, Bias:-0.19384583792878732, loss:0.6880497807169483\n",
            "Epoch:476, w1 : 0.35823331045400403, w2:0.32228325018321796, Bias:-0.19357318650867814, loss:0.6880491384849916\n",
            "Epoch:477, w1 : 0.357742252743193, w2:0.3222276251932849, Bias:-0.19330124938157875, loss:0.6880484996128564\n",
            "Epoch:478, w1 : 0.3572524809267334, w2:0.3221721477844699, Bias:-0.19303002468114877, loss:0.6880478640830152\n",
            "Epoch:479, w1 : 0.35676399166118095, w2:0.3221168175502155, Bias:-0.19275951054601237, loss:0.6880472318780316\n",
            "Epoch:480, w1 : 0.3562767816115482, w2:0.3220616340854445, Bias:-0.1924897051197415, loss:0.6880466029805603\n",
            "Epoch:481, w1 : 0.35579084745128686, w2:0.32200659698654566, Bias:-0.19222060655083922, loss:0.6880459773733446\n",
            "Epoch:482, w1 : 0.3553061858622706, w2:0.3219517058513594, Bias:-0.19195221299272325, loss:0.688045355039219\n",
            "Epoch:483, w1 : 0.3548227935347772, w2:0.3218969602791645, Bias:-0.19168452260370944, loss:0.6880447359611063\n",
            "Epoch:484, w1 : 0.3543406671674712, w2:0.32184235987066423, Bias:-0.19141753354699587, loss:0.6880441201220181\n",
            "Epoch:485, w1 : 0.35385980346738605, w2:0.3217879042279735, Bias:-0.1911512439906465, loss:0.6880435075050544\n",
            "Epoch:486, w1 : 0.35338019914990654, w2:0.32173359295460574, Bias:-0.19088565210757547, loss:0.6880428980934029\n",
            "Epoch:487, w1 : 0.3529018509387509, w2:0.3216794256554606, Bias:-0.19062075607553117, loss:0.6880422918703386\n",
            "Epoch:488, w1 : 0.35242475556595326, w2:0.32162540193681133, Bias:-0.19035655407708063, loss:0.6880416888192233\n",
            "Epoch:489, w1 : 0.35194890977184545, w2:0.3215715214062929, Bias:-0.19009304429959406, loss:0.6880410889235057\n",
            "Epoch:490, w1 : 0.3514743103050396, w2:0.32151778367289013, Bias:-0.1898302249352294, loss:0.6880404921667197\n",
            "Epoch:491, w1 : 0.3510009539224099, w2:0.321464188346926, Bias:-0.18956809418091713, loss:0.6880398985324854\n",
            "Epoch:492, w1 : 0.35052883738907464, w2:0.32141073504005063, Bias:-0.18930665023834498, loss:0.6880393080045074\n",
            "Epoch:493, w1 : 0.35005795747837865, w2:0.3213574233652297, Bias:-0.18904589131394312, loss:0.6880387205665761\n",
            "Epoch:494, w1 : 0.34958831097187487, w2:0.32130425293673404, Bias:-0.1887858156188691, loss:0.6880381362025645\n",
            "Epoch:495, w1 : 0.3491198946593066, w2:0.32125122337012874, Bias:-0.1885264213689931, loss:0.6880375548964305\n",
            "Epoch:496, w1 : 0.3486527053385894, w2:0.3211983342822627, Bias:-0.18826770678488342, loss:0.6880369766322153\n",
            "Epoch:497, w1 : 0.34818673981579296, w2:0.3211455852912586, Bias:-0.1880096700917916, loss:0.6880364013940427\n",
            "Epoch:498, w1 : 0.3477219949051231, w2:0.3210929760165026, Bias:-0.18775230951963826, loss:0.688035829166119\n",
            "Epoch:499, w1 : 0.34725846742890376, w2:0.3210405060786349, Bias:-0.18749562330299863, loss:0.6880352599327327\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.34725846742890376),\n",
              " np.float64(0.3210405060786349),\n",
              " np.float64(-0.18749562330299863))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating fit method without tensorflow**"
      ],
      "metadata": {
        "id": "UgtaAoxu58RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class my_custom_NN:\n",
        "       def __init__(self):\n",
        "         self.w1 = 1\n",
        "         self.w2 = 1\n",
        "         self.bias = 0\n",
        "\n",
        "       def fit(self, x, y, epochs):\n",
        "          self.w1, self.w2, self.bias = self.gradient_descent(x[\"Age\"], x[\"Affordibility\"], y, epochs)\n",
        "\n",
        "       def predict(self, x_test):\n",
        "           weighted_sum = self.w1 * x_test[\"Age\"] + self.w2 * x_test[\"Affordibility\"] + self.bias\n",
        "           return sigmoid_numpy(weighted_sum)\n",
        "\n",
        "       def gradient_descent(self, age, affordibility, y_true, epochs):\n",
        "           w1 = w2 = 1\n",
        "           bias = 0\n",
        "           rate = 0.5#learning rate\n",
        "           sample_len = len(age)\n",
        "\n",
        "           for i in range(epochs):\n",
        "             weighted_sum = w1 * age + w2 * affordibility + bias\n",
        "             y_predicted = sigmoid_numpy(weighted_sum)\n",
        "\n",
        "             loss = log_loss(y_true, y_predicted)\n",
        "\n",
        "             derivative_w1 = (1/sample_len) * np.dot(np.transpose(age), (y_predicted - y_true))\n",
        "             derivative_w2 = (1/sample_len) * np.dot(np.transpose(affordibility), (y_predicted - y_true))\n",
        "             derivative_bias = np.mean(y_predicted - y_true)\n",
        "\n",
        "             w1 = w1 - rate* derivative_w1\n",
        "             w2 = w2 - rate* derivative_w2\n",
        "             bias = bias - rate* derivative_bias\n",
        "\n",
        "             print(f\"Epoch:{i}, w1 : {w1}, w2:{w2}, Bias:{bias}, loss:{loss}\")\n",
        "\n",
        "           return w1, w2, bias\n",
        "\n"
      ],
      "metadata": {
        "id": "8v9L-cmo7_FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model = my_custom_NN()\n",
        "custom_model.fit(x_train_scaled, y_train, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sdT4pPjPIAdV",
        "outputId": "bc41a720-ab4f-4dcc-d263-e9abd33296e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0, w1 : 0.9547718165442592, w2:0.9408295195534853, Bias:-0.09110665735771768, loss:0.7808026615418449\n",
            "Epoch:1, w1 : 0.9161337154378755, w2:0.8885521463695576, Bias:-0.16856946189722624, loss:0.7550340778716349\n",
            "Epoch:2, w1 : 0.8834710360721807, w2:0.8427719613501229, Bias:-0.2336593373208486, loss:0.7360960830049563\n",
            "Epoch:3, w1 : 0.856101324999775, w2:0.8029361469503108, Bias:-0.28778778602452404, loss:0.7224473960757584\n",
            "Epoch:4, w1 : 0.8333310428397971, w2:0.768409322894624, Bias:-0.3323891210821248, loss:0.7127638979538975\n",
            "Epoch:5, w1 : 0.8144965539599085, w2:0.7385350569812978, Bias:-0.36883541613685017, loss:0.7059754961340622\n",
            "Epoch:6, w1 : 0.7989893253050251, w2:0.7126794811712769, Bias:-0.39838434254620836, loss:0.7012570759815172\n",
            "Epoch:7, w1 : 0.7862682282696151, w2:0.6902578733368477, Bias:-0.4221538267666259, loss:0.6979948197851018\n",
            "Epoch:8, w1 : 0.7758627051289785, w2:0.6707478229129349, Bias:-0.4411156583723295, loss:0.6957443299659516\n",
            "Epoch:9, w1 : 0.7673702060120836, w2:0.6536931056501973, Bias:-0.45610094367197207, loss:0.6941903816253351\n",
            "Epoch:10, w1 : 0.7604504876260623, w2:0.638701790185872, Bias:-0.467812016833409, loss:0.6931127832921994\n",
            "Epoch:11, w1 : 0.7548185339362682, w2:0.6254411731590142, Bias:-0.47683716091789136, loss:0.6923594859562072\n",
            "Epoch:12, w1 : 0.7502371910824754, w2:0.6136312796330334, Bias:-0.4836658839243487, loss:0.6918263947009821\n",
            "Epoch:13, w1 : 0.7465101351580845, w2:0.6030380025411137, Bias:-0.4887034786956043, loss:0.6914426998091978\n",
            "Epoch:14, w1 : 0.7434754821581685, w2:0.593466493611631, Bias:-0.4922842355596593, loss:0.6911604600671363\n",
            "Epoch:15, w1 : 0.7410001601066394, w2:0.5847551188022705, Bias:-0.4946830667234869, loss:0.6909473263440711\n",
            "Epoch:16, w1 : 0.7389750546439388, w2:0.5767701074064088, Bias:-0.49612552452778325, loss:0.6907815193950787\n",
            "Epoch:17, w1 : 0.7373108816980309, w2:0.5694009171483357, Bias:-0.49679631327009544, loss:0.6906483941877134\n",
            "Epoch:18, w1 : 0.7359347141333553, w2:0.5625562796725309, Bias:-0.49684644825741575, loss:0.6905381051700219\n",
            "Epoch:19, w1 : 0.734787080468207, w2:0.556160862832998, Bias:-0.4963992329781093, loss:0.6904440276870509\n",
            "Epoch:20, w1 : 0.7338195547910678, w2:0.550152475790162, Bias:-0.4955552224485106, loss:0.6903616947772394\n",
            "Epoch:21, w1 : 0.7329927630267064, w2:0.544479742411066, Bias:-0.49439632788481946, loss:0.6902880832240842\n",
            "Epoch:22, w1 : 0.7322747388633681, w2:0.5391001731369067, Bias:-0.4929892006873762, loss:0.6902211352452321\n",
            "Epoch:23, w1 : 0.7316395713544711, w2:0.5339785725328309, Bias:-0.49138801555744166, loss:0.6901594386215706\n",
            "Epoch:24, w1 : 0.7310662945988021, w2:0.529085727557296, Bias:-0.48963675512223187, loss:0.6901020130760163\n",
            "Epoch:25, w1 : 0.7305379775676557, w2:0.5243973292952242, Bias:-0.4877710825519849, loss:0.6900481677535515\n",
            "Epoch:26, w1 : 0.7300409789226323, w2:0.5198930880379666, Bias:-0.48581987463125703, loss:0.6899974062021306\n",
            "Epoch:27, w1 : 0.7295643375301354, w2:0.5155560079659378, Bias:-0.4838064756316132, loss:0.6899493630454908\n",
            "Epoch:28, w1 : 0.7290992743769665, w2:0.5113717932440198, Bias:-0.48174972201456323, loss:0.6899037617780307\n",
            "Epoch:29, w1 : 0.7286387858087784, w2:0.5073283621016659, Bias:-0.47966477929495827, loss:0.6898603866255346\n",
            "Epoch:30, w1 : 0.7281773115444142, w2:0.5034154495045462, Bias:-0.47756382511649403, loss:0.6898190637669169\n",
            "Epoch:31, w1 : 0.7277104638590804, w2:0.49962428241431295, Bias:-0.47545660653457167, loss:0.689779648783147\n",
            "Epoch:32, w1 : 0.7272348067662554, w2:0.4959473144625068, Bias:-0.47335089448369694, loss:0.6897420182476404\n",
            "Epoch:33, w1 : 0.7267476760414954, w2:0.4923780092148422, Bias:-0.47125285426246183, loss:0.6897060640709027\n",
            "Epoch:34, w1 : 0.7262470325901454, w2:0.488910663146862, Bias:-0.46916734745552413, loss:0.6896716896772797\n",
            "Epoch:35, w1 : 0.725731343024939, w2:0.48554026105641895, Bias:-0.46709817790581054, loss:0.6896388074010872\n",
            "Epoch:36, w1 : 0.725199482439128, w2:0.4822623579590588, Bias:-0.4650482920470714, loss:0.6896073366951031\n",
            "Epoch:37, w1 : 0.7246506552786461, w2:0.47907298259732184, Bias:-0.4630199420191879, loss:0.6895772028811055\n",
            "Epoch:38, w1 : 0.724084330968423, w2:0.4759685585849649, Bias:-0.46101481844300796, loss:0.6895483362629461\n",
            "Epoch:39, w1 : 0.7235001915628911, w2:0.4729458399362665, Bias:-0.4590341584670744, loss:0.6895206714829248\n",
            "Epoch:40, w1 : 0.7228980891934527, w2:0.47000185832738456, Bias:-0.4570788336649916, loss:0.6894941470422519\n",
            "Epoch:41, w1 : 0.7222780114964066, w2:0.4671338799248064, Bias:-0.4551494215177339, loss:0.6894687049329459\n",
            "Epoch:42, w1 : 0.7216400535402522, w2:0.4643393700148081, Bias:-0.45324626352565855, loss:0.6894442903461181\n",
            "Epoch:43, w1 : 0.7209843950450575, w2:0.4616159639936349, Bias:-0.451369512432171, loss:0.689420851433302\n",
            "Epoch:44, w1 : 0.7203112819099705, w2:0.4589614435440955, Bias:-0.4495191705817825, loss:0.6893983391052275\n",
            "Epoch:45, w1 : 0.7196210112471593, w2:0.4563737170413161, Bias:-0.44769512106074083, loss:0.6893767068575976\n",
            "Epoch:46, w1 : 0.7189139192690538, w2:0.4538508034074736, Bias:-0.4458971529629854, loss:0.6893559106168309\n",
            "Epoch:47, w1 : 0.7181903714968931, w2:0.4513908187797359, Bias:-0.44412498187517835, loss:0.6893359086010115\n",
            "Epoch:48, w1 : 0.7174507548573161, w2:0.44899196547337866, Bias:-0.4423782664716131, loss:0.6893166611927911\n",
            "Epoch:49, w1 : 0.7166954713141926, w2:0.446652522818027, Bias:-0.4406566219444083, loss:0.6892981308219918\n",
            "Epoch:50, w1 : 0.7159249327484499, w2:0.44437083952319184, Bias:-0.43895963085964235, loss:0.6892802818563305\n",
            "Epoch:51, w1 : 0.7151395568520535, w2:0.4421453272930104, Bias:-0.43728685192030003, loss:0.6892630804991339\n",
            "Epoch:52, w1 : 0.7143397638458059, w2:0.4399744554620299, Bias:-0.4356378270274836, loss:0.6892464946932105\n",
            "Epoch:53, w1 : 0.7135259738660527, w2:0.43785674646617856, Bias:-0.4340120869585099, loss:0.689230494030255\n",
            "Epoch:54, w1 : 0.7126986048942394, w2:0.4357907719975248, Bias:-0.4324091559212101, loss:0.6892150496652908\n",
            "Epoch:55, w1 : 0.7118580711267526, w2:0.43377514971948855, Bias:-0.4308285551954544, loss:0.6892001342357617\n",
            "Epoch:56, w1 : 0.7110047817016042, w2:0.4318085404420221, Bias:-0.42926980603360804, loss:0.6891857217849419\n",
            "Epoch:57, w1 : 0.7101391397140914, w2:0.42988964567488835, Bias:-0.42773243195961635, loss:0.6891717876893877\n",
            "Epoch:58, w1 : 0.7092615414662334, w2:0.42801720549231487, Bias:-0.4262159605803601, loss:0.689158308590182\n",
            "Epoch:59, w1 : 0.7083723759051066, w2:0.4261899966546402, Bias:-0.42471992500171635, loss:0.6891452623277535\n",
            "Epoch:60, w1 : 0.70747202421359, w2:0.42440683094261167, Bias:-0.4232438649244988, loss:0.6891326278800732\n",
            "Epoch:61, w1 : 0.70656085952387, w2:0.4226665536681709, Bias:-0.42178732748140463, loss:0.689120385304042\n",
            "Epoch:62, w1 : 0.7056392467296073, w2:0.4209680423322189, Bias:-0.42034986786466544, loss:0.6891085156799007\n",
            "Epoch:63, w1 : 0.7047075423771948, w2:0.41931020540527253, Bias:-0.4189310497847981, loss:0.6890970010585039\n",
            "Epoch:64, w1 : 0.7037660946202132, w2:0.41769198121133355, Bias:-0.4175304457932856, loss:0.689085824411304\n",
            "Epoch:65, w1 : 0.7028152432241861, w2:0.4161123368988844, Bias:-0.41614763749586026, loss:0.689074969582914\n",
            "Epoch:66, w1 : 0.7018553196111672, w2:0.41457026748584636, Bias:-0.41478221567805545, loss:0.6890644212461039\n",
            "Epoch:67, w1 : 0.7008866469356767, w2:0.413064794967718, Bias:-0.4134337803606165, loss:0.6890541648591176\n",
            "Epoch:68, w1 : 0.6999095401851106, w2:0.4115949674800481, Bias:-0.4121019407990506, loss:0.6890441866251803\n",
            "Epoch:69, w1 : 0.6989243062990578, w2:0.4101598585079769, Bias:-0.41078631543889865, loss:0.6890344734540929\n",
            "Epoch:70, w1 : 0.6979312443030218, w2:0.40875856613686384, Bias:-0.4094865318361231, loss:0.6890250129257993\n",
            "Epoch:71, w1 : 0.6969306454529132, w2:0.4073902123390679, Bias:-0.40820222655022265, loss:0.689015793255832\n",
            "Epoch:72, w1 : 0.6959227933873762, w2:0.4060539422928, Bias:-0.406933045016237, loss:0.6890068032625313\n",
            "Epoch:73, w1 : 0.6949079642855893, w2:0.4047489237296618, Bias:-0.4056786414006278, loss:0.688998032335958\n",
            "Epoch:74, w1 : 0.6938864270286408, w2:0.4034743463080533, Bias:-0.4044386784450635, loss:0.6889894704084023\n",
            "Epoch:75, w1 : 0.6928584433629571, w2:0.4022294210100939, Bias:-0.40321282730136, loss:0.6889811079264134\n",
            "Epoch:76, w1 : 0.6918242680645699, w2:0.40101337956007993, Bias:-0.40200076736019585, loss:0.6889729358242705\n",
            "Epoch:77, w1 : 0.6907841491032526, w2:0.39982547386280953, Bias:-0.40080218607570806, loss:0.6889649454988193\n",
            "Epoch:78, w1 : 0.6897383278057625, w2:0.39866497546035945, Bias:-0.39961677878765706, loss:0.6889571287856064\n",
            "Epoch:79, w1 : 0.6886870390175835, w2:0.3975311750061038, Bias:-0.3984442485425121, loss:0.6889494779362441\n",
            "Epoch:80, w1 : 0.6876305112627006, w2:0.39642338175493497, Bias:-0.3972843059145332, loss:0.6889419855969398\n",
            "Epoch:81, w1 : 0.6865689669010413, w2:0.39534092306878577, Bias:-0.396136668827702, loss:0.6889346447881373\n",
            "Epoch:82, w1 : 0.6855026222833088, w2:0.3942831439366662, Bias:-0.39500106237917526, loss:0.6889274488852022\n",
            "Epoch:83, w1 : 0.6844316879029977, w2:0.39324940650852297, Bias:-0.3938772186647863, loss:0.688920391600108\n",
            "Epoch:84, w1 : 0.6833563685454433, w2:0.39223908964230714, Bias:-0.3927648766070027, loss:0.688913466964065\n",
            "Epoch:85, w1 : 0.6822768634337992, w2:0.39125158846370056, Bias:-0.3916637817856517, loss:0.6889066693110462\n",
            "Epoch:86, w1 : 0.6811933663718734, w2:0.39028631393800545, Bias:-0.39057368627164785, loss:0.6888999932621639\n",
            "Epoch:87, w1 : 0.680106065883785, w2:0.3893426924537454, Bias:-0.3894943484638945, loss:0.6888934337108495\n",
            "Epoch:88, w1 : 0.6790151453504241, w2:0.3884201654175657, Bias:-0.3884255329294808, loss:0.6888869858088046\n",
            "Epoch:89, w1 : 0.6779207831427192, w2:0.38751818886005024, Bias:-0.38736701024725406, loss:0.6888806449526691\n",
            "Epoch:90, w1 : 0.6768231527517277, w2:0.38663623305210154, Bias:-0.38631855685481725, loss:0.6888744067713862\n",
            "Epoch:91, w1 : 0.6757224229155795, w2:0.3857737821315515, Bias:-0.3852799548989723, loss:0.6888682671142133\n",
            "Epoch:92, w1 : 0.6746187577433118, w2:0.3849303337396915, Bias:-0.3842509920896118, loss:0.6888622220393553\n",
            "Epoch:93, w1 : 0.6735123168356397, w2:0.38410539866742693, Bias:-0.38323146155704313, loss:0.6888562678031847\n",
            "Epoch:94, w1 : 0.6724032554027131, w2:0.3832985005107769, Bias:-0.3822211617127179, loss:0.6888504008500167\n",
            "Epoch:95, w1 : 0.6712917243789144, w2:0.3825091753354518, Bias:-0.3812198961133277, loss:0.688844617802416\n",
            "Epoch:96, w1 : 0.670177870534755, w2:0.38173697135025453, Bias:-0.38022747332822004, loss:0.6888389154520008\n",
            "Epoch:97, w1 : 0.6690618365859287, w2:0.3809814485890603, Bias:-0.3792437068100831, loss:0.688833290750724\n",
            "Epoch:98, w1 : 0.667943761299583, w2:0.3802421786011403, Bias:-0.3782684147688414, loss:0.688827740802605\n",
            "Epoch:99, w1 : 0.6668237795978712, w2:0.3795187441496029, Bias:-0.3773014200487023, loss:0.6888222628558873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model.predict(x_test_scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "wAXFx6mZMv-E",
        "outputId": "4dd9df6a-ebf0-428a-9352-7c39a55e6283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17    0.599243\n",
              "33    0.633907\n",
              "32    0.538960\n",
              "10    0.445897\n",
              "16    0.581507\n",
              "21    0.592821\n",
              "27    0.556986\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.599243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.633907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.538960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.445897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.581507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.592821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.556986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_test_scaled)"
      ],
      "metadata": {
        "id": "MNloo94wRxMX",
        "outputId": "b56090ce-1310-4469-8adf-9e476e8dad1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6603124 ],\n",
              "       [0.691542  ],\n",
              "       [0.5428289 ],\n",
              "       [0.45230153],\n",
              "       [0.64413595],\n",
              "       [0.6544709 ],\n",
              "       [0.62154216]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}